{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10a47a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as slin\n",
    "import scipy.optimize as sopt\n",
    "\n",
    "from structuremodel import StructureModel\n",
    "from transformers import DynamicDataTransformer\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165c73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_pandas_dynamic(  # pylint: disable=too-many-arguments\n",
    "    time_series: Union[pd.DataFrame, List[pd.DataFrame]],\n",
    "    p: int,\n",
    "    lambda_w: float = 0.1,\n",
    "    lambda_a: float = 0.1,\n",
    "    max_iter: int = 100,\n",
    "    h_tol: float = 1e-8,\n",
    "    w_threshold: float = 0.0,\n",
    "    tabu_edges: List[Tuple[int, int, int]] = None,\n",
    "    tabu_parent_nodes: List[int] = None,\n",
    "    tabu_child_nodes: List[int] = None,\n",
    ") -> StructureModel:\n",
    "    \"\"\"\n",
    "    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between variables in\n",
    "    data. The input data is a time series or a list of realisations of a same time series.\n",
    "    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n",
    "    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n",
    "    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n",
    "    encapsulated how acyclic the graph is (less = more acyclic).\n",
    "    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n",
    "    https://arxiv.org/abs/2002.00498\n",
    "    @inproceedings{pamfil2020dynotears,\n",
    "        title={DYNOTEARS: Structure Learning from Time-Series Data},\n",
    "        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n",
    "        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n",
    "        booktitle={International Conference on Artificial Intelligence and Statistics},\n",
    "        pages={1595--1605},\n",
    "        year={2020}year={2020},\n",
    "    }\n",
    "    Args:\n",
    "        time_series: pd.DataFrame or List of pd.DataFrame instances.\n",
    "        If a list is provided each element of the list being an realisation of a time series (i.e. time series governed\n",
    "        by the same processes)\n",
    "        The columns of the data frame represent the variables in the model, and the *index represents the time index*.\n",
    "        Successive events, therefore, must be indexed with one integer of difference between them too.\n",
    "        p: Number of past interactions we allow the model to create. The state of a variable at time `t` is affected by\n",
    "        past variables up to a `t-p`, as well as by other variables at `t`.\n",
    "        lambda_w: parameter for l1 regularisation of intra-slice edges\n",
    "        lambda_a: parameter for l1 regularisation of inter-slice edges\n",
    "        max_iter: max number of dual ascent steps during optimisation.\n",
    "        h_tol: exit if h(W) < h_tol (as opposed to strict definition of 0).\n",
    "        w_threshold: fixed threshold for absolute edge weights.\n",
    "        tabu_edges: list of edges(lag, from, to) not to be included in the graph. `lag == 0` implies that the edge is\n",
    "        forbidden in the INTRA graph (W), while lag > 0 implies an INTER-slice weight equal zero.\n",
    "        tabu_parent_nodes: list of nodes banned from being a parent of any other nodes.\n",
    "        tabu_child_nodes: list of nodes banned from being a child of any other nodes.\n",
    "    Returns:\n",
    "        StructureModel representing the model learnt. The node names are noted as `{var}_lag{l}`, where `var` is the\n",
    "        original variable name as in the give in the input data frames and `l`, in 0,1,2..p is the correspondent\n",
    "        time lag.\n",
    "    \"\"\"\n",
    "    time_series = [time_series] if not isinstance(time_series, list) else time_series\n",
    "\n",
    "    X, Xlags = DynamicDataTransformer(p=p).fit_transform(time_series, return_df=False)\n",
    "\n",
    "    col_idx = {c: i for i, c in enumerate(time_series[0].columns)}\n",
    "    idx_col = {i: c for c, i in col_idx.items()}\n",
    "\n",
    "    if tabu_edges:\n",
    "        tabu_edges = [(lag, col_idx[u], col_idx[v]) for lag, u, v in tabu_edges]\n",
    "    if tabu_parent_nodes:\n",
    "        tabu_parent_nodes = [col_idx[n] for n in tabu_parent_nodes]\n",
    "    if tabu_child_nodes:\n",
    "        tabu_child_nodes = [col_idx[n] for n in tabu_child_nodes]\n",
    "\n",
    "    g = from_numpy_dynamic(\n",
    "        X,\n",
    "        Xlags,\n",
    "        lambda_w,\n",
    "        lambda_a,\n",
    "        max_iter,\n",
    "        h_tol,\n",
    "        w_threshold,\n",
    "        tabu_edges,\n",
    "        tabu_parent_nodes,\n",
    "        tabu_child_nodes,\n",
    "    )\n",
    "\n",
    "    sm = StructureModel()\n",
    "    sm.add_nodes_from(\n",
    "        [f\"{var}_lag{l_val}\" for var in col_idx.keys() for l_val in range(p + 1)]\n",
    "    )\n",
    "    sm.add_weighted_edges_from(\n",
    "        [\n",
    "            (\n",
    "                _format_name_from_pandas(idx_col, u),\n",
    "                _format_name_from_pandas(idx_col, v),\n",
    "                w,\n",
    "            )\n",
    "            for u, v, w in g.edges.data(\"weight\")\n",
    "        ],\n",
    "        origin=\"learned\",\n",
    "    )\n",
    "\n",
    "    return sm\n",
    "\n",
    "\n",
    "def _format_name_from_pandas(idx_col: Dict[int, str], from_numpy_node: str) -> str:\n",
    "    \"\"\"\n",
    "    Helper function for `from_pandas_dynamic`. converts a node from the `from_numpy_dynamic` format to the `from_pandas`\n",
    "    format\n",
    "    Args:\n",
    "        idx_col: map from variable to intdex\n",
    "        from_numpy_node: nodes in the structure model output by `from_numpy_dynamic`.\n",
    "    Returns:\n",
    "        nodes in from_pandas_dynamic format\n",
    "    \"\"\"\n",
    "    idx, lag_val = from_numpy_node.split(\"_lag\")\n",
    "    return f\"{idx_col[int(idx)]}_lag{lag_val}\"\n",
    "\n",
    "\n",
    "def from_numpy_dynamic(  # pylint: disable=too-many-arguments\n",
    "    X: np.ndarray,\n",
    "    Xlags: np.ndarray,\n",
    "    lambda_w: float = 0.1,\n",
    "    lambda_a: float = 0.1,\n",
    "    max_iter: int = 100,\n",
    "    h_tol: float = 1e-8,\n",
    "    w_threshold: float = 0.0,\n",
    "    tabu_edges: List[Tuple[int, int, int]] = None,\n",
    "    tabu_parent_nodes: List[int] = None,\n",
    "    tabu_child_nodes: List[int] = None,\n",
    ") -> StructureModel:\n",
    "    \"\"\"\n",
    "    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between variables in\n",
    "    data. The input data is time series data present in numpy arrays X and Xlags.\n",
    "    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n",
    "    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n",
    "    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n",
    "    encapsulated how acyclic the graph is (less = more acyclic).\n",
    "    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n",
    "    https://arxiv.org/abs/2002.00498\n",
    "    @inproceedings{pamfil2020dynotears,\n",
    "        title={DYNOTEARS: Structure Learning from Time-Series Data},\n",
    "        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n",
    "        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n",
    "        booktitle={International Conference on Artificial Intelligence and Statistics},\n",
    "        pages={1595--1605},\n",
    "        year={2020}year={2020},\n",
    "    }\n",
    "    Args:\n",
    "        X (np.ndarray): 2d input data, axis=1 is data columns, axis=0 is data rows. Each column represents one variable,\n",
    "        and each row represents x(m,t) i.e. the mth time series at time t.\n",
    "        Xlags (np.ndarray): shifted data of X with lag orders stacking horizontally. Xlags=[shift(X,1)|...|shift(X,p)]\n",
    "        lambda_w (float): l1 regularization parameter of intra-weights W\n",
    "        lambda_a (float): l1 regularization parameter of inter-weights A\n",
    "        max_iter: max number of dual ascent steps during optimisation\n",
    "        h_tol (float): exit if h(W) < h_tol (as opposed to strict definition of 0)\n",
    "        w_threshold: fixed threshold for absolute edge weights.\n",
    "        tabu_edges: list of edges(lag, from, to) not to be included in the graph. `lag == 0` implies that the edge is\n",
    "        forbidden in the INTRA graph (W), while lag > 0 implies an INTER weight equal zero.\n",
    "        tabu_parent_nodes: list of nodes banned from being a parent of any other nodes.\n",
    "        tabu_child_nodes: list of nodes banned from being a child of any other nodes.\n",
    "    Returns:\n",
    "        W (np.ndarray): d x d estimated weighted adjacency matrix of intra slices\n",
    "        A (np.ndarray): d x pd estimated weighted adjacency matrix of inter slices\n",
    "    Raises:\n",
    "        ValueError: If X or Xlags does not contain data, or dimensions of X and Xlags do not conform\n",
    "    \"\"\"\n",
    "    _, d_vars = X.shape\n",
    "    p_orders = Xlags.shape[1] // d_vars\n",
    "\n",
    "    bnds_w = 2 * [\n",
    "        (0, 0)\n",
    "        if i == j\n",
    "        else (0, 0)\n",
    "        if tabu_edges is not None and (0, i, j) in tabu_edges\n",
    "        else (0, 0)\n",
    "        if tabu_parent_nodes is not None and i in tabu_parent_nodes\n",
    "        else (0, 0)\n",
    "        if tabu_child_nodes is not None and j in tabu_child_nodes\n",
    "        else (0, None)\n",
    "        for i in range(d_vars)\n",
    "        for j in range(d_vars)\n",
    "    ]\n",
    "\n",
    "    bnds_a = []\n",
    "    for k in range(1, p_orders + 1):\n",
    "        bnds_a.extend(\n",
    "            2\n",
    "            * [\n",
    "                (0, 0)\n",
    "                if tabu_edges is not None and (k, i, j) in tabu_edges\n",
    "                else (0, 0)\n",
    "                if tabu_parent_nodes is not None and i in tabu_parent_nodes\n",
    "                else (0, 0)\n",
    "                if tabu_child_nodes is not None and j in tabu_child_nodes\n",
    "                else (0, None)\n",
    "                for i in range(d_vars)\n",
    "                for j in range(d_vars)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    bnds = bnds_w + bnds_a\n",
    "    w_est, a_est = _learn_dynamic_structure(\n",
    "        X, Xlags, bnds, lambda_w, lambda_a, max_iter, h_tol\n",
    "    )\n",
    "\n",
    "    w_est[np.abs(w_est) < w_threshold] = 0\n",
    "    a_est[np.abs(a_est) < w_threshold] = 0\n",
    "    #sm = _matrices_to_structure_model(w_est, a_est)\n",
    "    #return sm\n",
    "    return w_est, a_est\n",
    "\n",
    "\n",
    "def _matrices_to_structure_model(\n",
    "    w_est: np.ndarray, a_est: np.ndarray\n",
    ") -> StructureModel:\n",
    "    \"\"\"\n",
    "    Converts the matrices output by dynotears (W and A) into a StructureModel\n",
    "    We use the following convention:\n",
    "    - {var}_lag{l} where l is the lag value (i.e. from how many previous timestamps the edge is coming\n",
    "    - if we deal with a intra_slice_node, `l == 0`\n",
    "    Args:\n",
    "        w_est: Intra-slice weight matrix\n",
    "        a_est: Inter-slice matrix\n",
    "    Returns:\n",
    "        StructureModel representing the structure learnt\n",
    "    \"\"\"\n",
    "    sm = StructureModel()\n",
    "    lag_cols = [\n",
    "        f\"{var}_lag{l_val}\"\n",
    "        for l_val in range(1 + (a_est.shape[0] // a_est.shape[1]))\n",
    "        for var in range(a_est.shape[1])\n",
    "    ]\n",
    "    sm.add_nodes_from(lag_cols)\n",
    "    sm.add_edges_from(\n",
    "        [\n",
    "            (lag_cols[i], lag_cols[j], dict(weight=w_est[i, j]))\n",
    "            for i in range(w_est.shape[0])\n",
    "            for j in range(w_est.shape[1])\n",
    "            if w_est[i, j] != 0\n",
    "        ]\n",
    "    )\n",
    "    sm.add_edges_from(\n",
    "        [\n",
    "            (lag_cols[i + w_est.shape[0]], lag_cols[j], dict(weight=a_est[i, j]))\n",
    "            for i in range(a_est.shape[0])\n",
    "            for j in range(a_est.shape[1])\n",
    "            if a_est[i, j] != 0\n",
    "        ]\n",
    "    )\n",
    "    return sm\n",
    "\n",
    "\n",
    "def _reshape_wa(\n",
    "    wa_vec: np.ndarray, d_vars: int, p_orders: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Helper function for `_learn_dynamic_structure`. Transform adjacency vector to matrix form\n",
    "    Args:\n",
    "        wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n",
    "        d_vars (int): number of variables in the model\n",
    "        p_orders (int): number of past indexes we to use\n",
    "    Returns:\n",
    "        intra- and inter-slice adjacency matrices\n",
    "    \"\"\"\n",
    "\n",
    "    w_tilde = wa_vec.reshape([2 * (p_orders + 1) * d_vars, d_vars])\n",
    "    w_plus = w_tilde[:d_vars, :]\n",
    "    w_minus = w_tilde[d_vars : 2 * d_vars, :]\n",
    "    w_mat = w_plus - w_minus\n",
    "    a_plus = (\n",
    "        w_tilde[2 * d_vars :]\n",
    "        .reshape(2 * p_orders, d_vars**2)[::2]\n",
    "        .reshape(d_vars * p_orders, d_vars)\n",
    "    )\n",
    "    a_minus = (\n",
    "        w_tilde[2 * d_vars :]\n",
    "        .reshape(2 * p_orders, d_vars**2)[1::2]\n",
    "        .reshape(d_vars * p_orders, d_vars)\n",
    "    )\n",
    "    a_mat = a_plus - a_minus\n",
    "    return w_mat, a_mat\n",
    "\n",
    "\n",
    "def _learn_dynamic_structure(\n",
    "    X: np.ndarray,\n",
    "    Xlags: np.ndarray,\n",
    "    bnds: List[Tuple[float, float]],\n",
    "    lambda_w: float = 0.1,\n",
    "    lambda_a: float = 0.1,\n",
    "    max_iter: int = 100,\n",
    "    h_tol: float = 1e-8,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between data variables.\n",
    "    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n",
    "    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n",
    "    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n",
    "    encapsulated how acyclic the graph is (less = more acyclic).\n",
    "    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n",
    "    https://arxiv.org/abs/2002.00498\n",
    "    @inproceedings{pamfil2020dynotears,\n",
    "        title={DYNOTEARS: Structure Learning from Time-Series Data},\n",
    "        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n",
    "        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n",
    "        booktitle={International Conference on Artificial Intelligence and Statistics},\n",
    "        pages={1595--1605},\n",
    "        year={2020}year={2020},\n",
    "    }\n",
    "    Args:\n",
    "        X (np.ndarray): 2d input data, axis=1 is data columns, axis=0 is data rows. Each column represents one variable,\n",
    "        and each row represents x(m,t) i.e. the mth time series at time t.\n",
    "        Xlags (np.ndarray): shifted data of X with lag orders stacking horizontally. Xlags=[shift(X,1)|...|shift(X,p)]\n",
    "        bnds: Box constraints of L-BFGS-B to ban self-loops in W, enforce non-negativity of w_plus, w_minus, a_plus,\n",
    "        a_minus, and help with stationarity in A\n",
    "        lambda_w (float): l1 regularization parameter of intra-weights W\n",
    "        lambda_a (float): l1 regularization parameter of inter-weights A\n",
    "        max_iter (int): max number of dual ascent steps during optimisation\n",
    "        h_tol (float): exit if h(W) < h_tol (as opposed to strict definition of 0)\n",
    "    Returns:\n",
    "        W (np.ndarray): d x d estimated weighted adjacency matrix of intra slices\n",
    "        A (np.ndarray): d x pd estimated weighted adjacency matrix of inter slices\n",
    "    Raises:\n",
    "        ValueError: If X or Xlags does not contain data, or dimensions of X and Xlags do not conform\n",
    "    \"\"\"\n",
    "    if X.size == 0:\n",
    "        raise ValueError(\"Input data X is empty, cannot learn any structure\")\n",
    "    if Xlags.size == 0:\n",
    "        raise ValueError(\"Input data Xlags is empty, cannot learn any structure\")\n",
    "    if X.shape[0] != Xlags.shape[0]:\n",
    "        raise ValueError(\"Input data X and Xlags must have the same number of rows\")\n",
    "    if Xlags.shape[1] % X.shape[1] != 0:\n",
    "        raise ValueError(\n",
    "            \"Number of columns of Xlags must be a multiple of number of columns of X\"\n",
    "        )\n",
    "\n",
    "    n, d_vars = X.shape\n",
    "    p_orders = Xlags.shape[1] // d_vars\n",
    "\n",
    "    def _h(wa_vec: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Constraint function of the dynotears\n",
    "        Args:\n",
    "            wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n",
    "        Returns:\n",
    "            float: DAGness of the intra-slice adjacency matrix W (0 == DAG, >0 == cyclic)\n",
    "        \"\"\"\n",
    "\n",
    "        _w_mat, _ = _reshape_wa(wa_vec, d_vars, p_orders)\n",
    "        return np.trace(slin.expm(_w_mat * _w_mat)) - d_vars\n",
    "\n",
    "    def _func(wa_vec: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Objective function that the dynotears tries to minimise\n",
    "        Args:\n",
    "            wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n",
    "        Returns:\n",
    "            float: objective\n",
    "        \"\"\"\n",
    "\n",
    "        _w_mat, _a_mat = _reshape_wa(wa_vec, d_vars, p_orders)\n",
    "        loss = (\n",
    "            0.5\n",
    "            / n\n",
    "            * np.square(\n",
    "                np.linalg.norm(\n",
    "                    X.dot(np.eye(d_vars, d_vars) - _w_mat) - Xlags.dot(_a_mat), \"fro\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        _h_value = _h(wa_vec)\n",
    "        l1_penalty = lambda_w * (wa_vec[: 2 * d_vars**2].sum()) + lambda_a * (\n",
    "            wa_vec[2 * d_vars**2 :].sum()\n",
    "        )\n",
    "        return loss + 0.5 * rho * _h_value * _h_value + alpha * _h_value + l1_penalty\n",
    "\n",
    "    def _grad(wa_vec: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gradient function used to compute next step in dynotears\n",
    "        Args:\n",
    "            wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n",
    "        Returns:\n",
    "            gradient vector\n",
    "        \"\"\"\n",
    "\n",
    "        _w_mat, _a_mat = _reshape_wa(wa_vec, d_vars, p_orders)\n",
    "        e_mat = slin.expm(_w_mat * _w_mat)\n",
    "        loss_grad_w = (\n",
    "            -1.0\n",
    "            / n\n",
    "            * (X.T.dot(X.dot(np.eye(d_vars, d_vars) - _w_mat) - Xlags.dot(_a_mat)))\n",
    "        )\n",
    "        obj_grad_w = (\n",
    "            loss_grad_w\n",
    "            + (rho * (np.trace(e_mat) - d_vars) + alpha) * e_mat.T * _w_mat * 2\n",
    "        )\n",
    "        obj_grad_a = (\n",
    "            -1.0\n",
    "            / n\n",
    "            * (Xlags.T.dot(X.dot(np.eye(d_vars, d_vars) - _w_mat) - Xlags.dot(_a_mat)))\n",
    "        )\n",
    "\n",
    "        grad_vec_w = np.append(\n",
    "            obj_grad_w, -obj_grad_w, axis=0\n",
    "        ).flatten() + lambda_w * np.ones(2 * d_vars**2)\n",
    "        grad_vec_a = obj_grad_a.reshape(p_orders, d_vars**2)\n",
    "        grad_vec_a = np.hstack(\n",
    "            (grad_vec_a, -grad_vec_a)\n",
    "        ).flatten() + lambda_a * np.ones(2 * p_orders * d_vars**2)\n",
    "        return np.append(grad_vec_w, grad_vec_a, axis=0)\n",
    "\n",
    "    # initialise matrix, weights and constraints\n",
    "    wa_est = np.zeros(2 * (p_orders + 1) * d_vars**2)\n",
    "    wa_new = np.zeros(2 * (p_orders + 1) * d_vars**2)\n",
    "    rho, alpha, h_value, h_new = 1.0, 0.0, np.inf, np.inf\n",
    "\n",
    "    for n_iter in range(max_iter):\n",
    "        while (rho < 1e20) and (h_new > 0.25 * h_value or h_new == np.inf):\n",
    "            wa_new = sopt.minimize(\n",
    "                _func, wa_est, method=\"L-BFGS-B\", jac=_grad, bounds=bnds\n",
    "            ).x\n",
    "            h_new = _h(wa_new)\n",
    "            if h_new > 0.25 * h_value:\n",
    "                rho *= 10\n",
    "\n",
    "        wa_est = wa_new\n",
    "        h_value = h_new\n",
    "        alpha += rho * h_value\n",
    "        if h_value <= h_tol:\n",
    "            break\n",
    "        if h_value > h_tol and n_iter == max_iter - 1:\n",
    "            warnings.warn(\"Failed to converge. Consider increasing max_iter.\")\n",
    "    return _reshape_wa(wa_est, d_vars, p_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc8015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import scipy.linalg as slin\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import glob\n",
    "import re\n",
    "import math\n",
    "from torch.optim.adam import Adam\n",
    "from statistics import mean\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a21f8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_lsem_dynamic(W_all,Z: nx.DiGraph,\n",
    "                 n: int,n_time:int, treatment_type: str,\n",
    "                 noise_scale: float = 0.5,\n",
    "                 baseline: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Simulate samples from LSEM.\n",
    "        \n",
    "        Args:\n",
    "        W_all,A: weigthed DAG for instaneous relation and lagged relation\n",
    "        n: number of samples in each time-stamp\n",
    "        lag: degree of AR\n",
    "        n_time: number of time stamp\n",
    "        treatment_type: the type of the exposure {Binary, Gaussian}\n",
    "        noise_scale: noise scale parameter of Gaussian distribution in the lSEM\n",
    "        baseline: the baseline for the outcome\n",
    "        \n",
    "        Returns:\n",
    "        X: [time,n, d] sample matrix\n",
    "        \"\"\"\n",
    "    #W_array = nx.to_numpy_array(W)\n",
    "    Z_array = nx.to_numpy_array(Z)\n",
    "    d = Z_array.shape[0]\n",
    "    #X_all = np.zeros([n_time+1,n, d])\n",
    "    \n",
    "    ## create the initial data\n",
    "    X = np.zeros([n, d])\n",
    "    W_0=W_all[0,:,:]\n",
    "    ordered_vertices = list(nx.topological_sort(nx.from_numpy_matrix(W_0,create_using=nx.DiGraph)))\n",
    "    assert len(ordered_vertices) == d\n",
    "    rank_A = ordered_vertices.index(0)\n",
    "    for j in ordered_vertices:\n",
    "        if ordered_vertices.index(j) > rank_A:\n",
    "            parents = list(nx.from_numpy_matrix(W_0,create_using=nx.DiGraph).predecessors(j))\n",
    "            X[:, j] = X[:, parents].dot(W_0[parents, j]) + np.random.normal(scale=noise_scale, size=n)\n",
    "        elif ordered_vertices.index(j) < rank_A:\n",
    "            X[:, j] = np.random.normal(scale=noise_scale, size=n)\n",
    "        else:\n",
    "            if treatment_type == 'Binary':\n",
    "                X[:, j] = 2 * (np.random.binomial(1, 0.5, n) - 0.5)\n",
    "            elif treatment_type == 'Gaussian':\n",
    "                X[:, j] = np.random.normal(scale=noise_scale, size=n)\n",
    "            else:\n",
    "                raise ValueError('unknown exposure type')\n",
    "    X[:, d-1] += baseline\n",
    "    X_all=X\n",
    "    ## for follow-up time-stamps, X=XW+AZ+E\n",
    "    for time in range(1,n_time+1):\n",
    "        X_temp = np.matmul(X,Z_array)\n",
    "        W_array=W_all[time,:,:] ## different index!\n",
    "        W=nx.from_numpy_matrix(W_array,create_using=nx.DiGraph)\n",
    "        for j in ordered_vertices:\n",
    "            if ordered_vertices.index(j) > rank_A:\n",
    "                parents = list(W.predecessors(j))\n",
    "                X_temp[:, j] += X_temp[:, parents].dot(W_array[parents, j]) + np.random.normal(scale=noise_scale, size=n)\n",
    "            elif ordered_vertices.index(j) < rank_A:\n",
    "                X_temp[:, j] += np.random.normal(scale=noise_scale, size=n)\n",
    "            else:\n",
    "                if treatment_type == 'Binary':\n",
    "                    X_temp[:, j] += 2 * (np.random.binomial(1, 0.5, n) - 0.5)\n",
    "                elif treatment_type == 'Gaussian':\n",
    "                    X_temp[:, j] += np.random.normal(scale=noise_scale, size=n)\n",
    "                else:\n",
    "                    raise ValueError('unknown exposure type')\n",
    "        X_all=np.append(X_all,X_temp,axis=0)\n",
    "        X=X_temp\n",
    "    return X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748f64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_all=np.zeros([11,5, 5])\n",
    "import math \n",
    "def cos(x):\n",
    "    return(math.cos(x/4*math.pi)*0.8)\n",
    "for i in range(11):\n",
    "    W_all[i,0,4]=cos(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b3db741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create Z matrix\n",
    "Z=np.identity(5)\n",
    "Z[0,0]=0 # no correlation for treatment\n",
    "Z_graph=nx.from_numpy_matrix(Z,create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "125e47fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "p_orders=1\n",
    "d_vars=5\n",
    "n_var=5\n",
    "n_times=30 #no. of replicates\n",
    "time_stamp=10 #no. of timestamp\n",
    "np.random.seed(1234567) #Random seed\n",
    "seed_list=np.random.randint(1, 1000000, size=n_times)\n",
    "w_list=np.zeros((n_times,time_stamp,n_var, n_var))\n",
    "a_list=np.zeros((n_times,time_stamp,n_var, n_var))\n",
    "for replicate in range(n_times):\n",
    "  seed=seed_list[replicate]\n",
    "  X_all=simulate_lsem_dynamic(W_all,Z_graph,30,10, 'Binary',noise_scale=0.1)\n",
    "  for time in range(time_stamp):\n",
    "    X=X_all[(time+1)*30:(time+2)*30]\n",
    "    Y=X_all[(time)*30:(time+1)*30]\n",
    "    w,a=from_numpy_dynamic(X,Y)\n",
    "    w_list[replicate,time,:,:]=w\n",
    "    a_list[replicate,time,:,:]=a\n",
    "    np.save(\"result/dynotears_cos_w\",w_list)\n",
    "    np.save(\"result/dynotears_cos_a\",a_list)\n",
    "  print(replicate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fef93",
   "metadata": {},
   "source": [
    "## save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afcb0478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "p_orders=1\n",
    "d_vars=5\n",
    "n_var=5\n",
    "n_times=30 #no. of replicates\n",
    "time_stamp=10 #no. of timestamp\n",
    "np.random.seed(1234567) #Random seed\n",
    "seed_list=np.random.randint(1, 1000000, size=n_times)\n",
    "data=np.zeros((n_times,time_stamp,30,n_var))\n",
    "for replicate in range(n_times):\n",
    "#for replicate in range(1):\n",
    "  seed=seed_list[replicate]\n",
    "  X_all=simulate_lsem_dynamic(W_all,Z_graph,30,10, 'Binary',noise_scale=0.1)\n",
    "  for time in range(time_stamp):\n",
    "    X=X_all[(time+1)*30:(time+2)*30]\n",
    "    data[replicate,time,:,:]=X\n",
    "  print(replicate)\n",
    "  if replicate==0:\n",
    "        csv_data=data[0,:,:,:].reshape(300,5)##reshape to fit r data format\n",
    "  else:\n",
    "        csv_data=np.append(csv_data,data[replicate,:,:,:].reshape(300,5),axis=0)\n",
    "np.savetxt(\"data/cos.csv\",csv_data, delimiter=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
