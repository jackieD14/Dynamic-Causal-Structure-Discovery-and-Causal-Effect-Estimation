{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b10a47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as slin\n",
    "import scipy.optimize as sopt\n",
    "\n",
    "from structuremodel import StructureModel\n",
    "from transformers import DynamicDataTransformer\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "165c73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_pandas_dynamic(  # pylint: disable=too-many-arguments\n",
    "    time_series: Union[pd.DataFrame, List[pd.DataFrame]],\n",
    "    p: int,\n",
    "    lambda_w: float = 0.1,\n",
    "    lambda_a: float = 0.1,\n",
    "    max_iter: int = 100,\n",
    "    h_tol: float = 1e-8,\n",
    "    w_threshold: float = 0.0,\n",
    "    tabu_edges: List[Tuple[int, int, int]] = None,\n",
    "    tabu_parent_nodes: List[int] = None,\n",
    "    tabu_child_nodes: List[int] = None,\n",
    ") -> StructureModel:\n",
    "    \"\"\"\n",
    "    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between variables in\n",
    "    data. The input data is a time series or a list of realisations of a same time series.\n",
    "    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n",
    "    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n",
    "    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n",
    "    encapsulated how acyclic the graph is (less = more acyclic).\n",
    "    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n",
    "    https://arxiv.org/abs/2002.00498\n",
    "    @inproceedings{pamfil2020dynotears,\n",
    "        title={DYNOTEARS: Structure Learning from Time-Series Data},\n",
    "        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n",
    "        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n",
    "        booktitle={International Conference on Artificial Intelligence and Statistics},\n",
    "        pages={1595--1605},\n",
    "        year={2020}year={2020},\n",
    "    }\n",
    "    Args:\n",
    "        time_series: pd.DataFrame or List of pd.DataFrame instances.\n",
    "        If a list is provided each element of the list being an realisation of a time series (i.e. time series governed\n",
    "        by the same processes)\n",
    "        The columns of the data frame represent the variables in the model, and the *index represents the time index*.\n",
    "        Successive events, therefore, must be indexed with one integer of difference between them too.\n",
    "        p: Number of past interactions we allow the model to create. The state of a variable at time `t` is affected by\n",
    "        past variables up to a `t-p`, as well as by other variables at `t`.\n",
    "        lambda_w: parameter for l1 regularisation of intra-slice edges\n",
    "        lambda_a: parameter for l1 regularisation of inter-slice edges\n",
    "        max_iter: max number of dual ascent steps during optimisation.\n",
    "        h_tol: exit if h(W) < h_tol (as opposed to strict definition of 0).\n",
    "        w_threshold: fixed threshold for absolute edge weights.\n",
    "        tabu_edges: list of edges(lag, from, to) not to be included in the graph. `lag == 0` implies that the edge is\n",
    "        forbidden in the INTRA graph (W), while lag > 0 implies an INTER-slice weight equal zero.\n",
    "        tabu_parent_nodes: list of nodes banned from being a parent of any other nodes.\n",
    "        tabu_child_nodes: list of nodes banned from being a child of any other nodes.\n",
    "    Returns:\n",
    "        StructureModel representing the model learnt. The node names are noted as `{var}_lag{l}`, where `var` is the\n",
    "        original variable name as in the give in the input data frames and `l`, in 0,1,2..p is the correspondent\n",
    "        time lag.\n",
    "    \"\"\"\n",
    "    time_series = [time_series] if not isinstance(time_series, list) else time_series\n",
    "\n",
    "    X, Xlags = DynamicDataTransformer(p=p).fit_transform(time_series, return_df=False)\n",
    "\n",
    "    col_idx = {c: i for i, c in enumerate(time_series[0].columns)}\n",
    "    idx_col = {i: c for c, i in col_idx.items()}\n",
    "\n",
    "    if tabu_edges:\n",
    "        tabu_edges = [(lag, col_idx[u], col_idx[v]) for lag, u, v in tabu_edges]\n",
    "    if tabu_parent_nodes:\n",
    "        tabu_parent_nodes = [col_idx[n] for n in tabu_parent_nodes]\n",
    "    if tabu_child_nodes:\n",
    "        tabu_child_nodes = [col_idx[n] for n in tabu_child_nodes]\n",
    "\n",
    "    g = from_numpy_dynamic(\n",
    "        X,\n",
    "        Xlags,\n",
    "        lambda_w,\n",
    "        lambda_a,\n",
    "        max_iter,\n",
    "        h_tol,\n",
    "        w_threshold,\n",
    "        tabu_edges,\n",
    "        tabu_parent_nodes,\n",
    "        tabu_child_nodes,\n",
    "    )\n",
    "\n",
    "    sm = StructureModel()\n",
    "    sm.add_nodes_from(\n",
    "        [f\"{var}_lag{l_val}\" for var in col_idx.keys() for l_val in range(p + 1)]\n",
    "    )\n",
    "    sm.add_weighted_edges_from(\n",
    "        [\n",
    "            (\n",
    "                _format_name_from_pandas(idx_col, u),\n",
    "                _format_name_from_pandas(idx_col, v),\n",
    "                w,\n",
    "            )\n",
    "            for u, v, w in g.edges.data(\"weight\")\n",
    "        ],\n",
    "        origin=\"learned\",\n",
    "    )\n",
    "\n",
    "    return sm\n",
    "\n",
    "\n",
    "def _format_name_from_pandas(idx_col: Dict[int, str], from_numpy_node: str) -> str:\n",
    "    \"\"\"\n",
    "    Helper function for `from_pandas_dynamic`. converts a node from the `from_numpy_dynamic` format to the `from_pandas`\n",
    "    format\n",
    "    Args:\n",
    "        idx_col: map from variable to intdex\n",
    "        from_numpy_node: nodes in the structure model output by `from_numpy_dynamic`.\n",
    "    Returns:\n",
    "        nodes in from_pandas_dynamic format\n",
    "    \"\"\"\n",
    "    idx, lag_val = from_numpy_node.split(\"_lag\")\n",
    "    return f\"{idx_col[int(idx)]}_lag{lag_val}\"\n",
    "\n",
    "\n",
    "def from_numpy_dynamic(  # pylint: disable=too-many-arguments\n",
    "    X: np.ndarray,\n",
    "    Xlags: np.ndarray,\n",
    "    lambda_w: float = 0.1,\n",
    "    lambda_a: float = 0.1,\n",
    "    max_iter: int = 100,\n",
    "    h_tol: float = 1e-8,\n",
    "    w_threshold: float = 0.0,\n",
    "    tabu_edges: List[Tuple[int, int, int]] = None,\n",
    "    tabu_parent_nodes: List[int] = None,\n",
    "    tabu_child_nodes: List[int] = None,\n",
    ") -> StructureModel:\n",
    "    \"\"\"\n",
    "    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between variables in\n",
    "    data. The input data is time series data present in numpy arrays X and Xlags.\n",
    "    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n",
    "    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n",
    "    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n",
    "    encapsulated how acyclic the graph is (less = more acyclic).\n",
    "    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n",
    "    https://arxiv.org/abs/2002.00498\n",
    "    @inproceedings{pamfil2020dynotears,\n",
    "        title={DYNOTEARS: Structure Learning from Time-Series Data},\n",
    "        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n",
    "        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n",
    "        booktitle={International Conference on Artificial Intelligence and Statistics},\n",
    "        pages={1595--1605},\n",
    "        year={2020}year={2020},\n",
    "    }\n",
    "    Args:\n",
    "        X (np.ndarray): 2d input data, axis=1 is data columns, axis=0 is data rows. Each column represents one variable,\n",
    "        and each row represents x(m,t) i.e. the mth time series at time t.\n",
    "        Xlags (np.ndarray): shifted data of X with lag orders stacking horizontally. Xlags=[shift(X,1)|...|shift(X,p)]\n",
    "        lambda_w (float): l1 regularization parameter of intra-weights W\n",
    "        lambda_a (float): l1 regularization parameter of inter-weights A\n",
    "        max_iter: max number of dual ascent steps during optimisation\n",
    "        h_tol (float): exit if h(W) < h_tol (as opposed to strict definition of 0)\n",
    "        w_threshold: fixed threshold for absolute edge weights.\n",
    "        tabu_edges: list of edges(lag, from, to) not to be included in the graph. `lag == 0` implies that the edge is\n",
    "        forbidden in the INTRA graph (W), while lag > 0 implies an INTER weight equal zero.\n",
    "        tabu_parent_nodes: list of nodes banned from being a parent of any other nodes.\n",
    "        tabu_child_nodes: list of nodes banned from being a child of any other nodes.\n",
    "    Returns:\n",
    "        W (np.ndarray): d x d estimated weighted adjacency matrix of intra slices\n",
    "        A (np.ndarray): d x pd estimated weighted adjacency matrix of inter slices\n",
    "    Raises:\n",
    "        ValueError: If X or Xlags does not contain data, or dimensions of X and Xlags do not conform\n",
    "    \"\"\"\n",
    "    _, d_vars = X.shape\n",
    "    p_orders = Xlags.shape[1] // d_vars\n",
    "\n",
    "    bnds_w = 2 * [\n",
    "        (0, 0)\n",
    "        if i == j\n",
    "        else (0, 0)\n",
    "        if tabu_edges is not None and (0, i, j) in tabu_edges\n",
    "        else (0, 0)\n",
    "        if tabu_parent_nodes is not None and i in tabu_parent_nodes\n",
    "        else (0, 0)\n",
    "        if tabu_child_nodes is not None and j in tabu_child_nodes\n",
    "        else (0, None)\n",
    "        for i in range(d_vars)\n",
    "        for j in range(d_vars)\n",
    "    ]\n",
    "\n",
    "    bnds_a = []\n",
    "    for k in range(1, p_orders + 1):\n",
    "        bnds_a.extend(\n",
    "            2\n",
    "            * [\n",
    "                (0, 0)\n",
    "                if tabu_edges is not None and (k, i, j) in tabu_edges\n",
    "                else (0, 0)\n",
    "                if tabu_parent_nodes is not None and i in tabu_parent_nodes\n",
    "                else (0, 0)\n",
    "                if tabu_child_nodes is not None and j in tabu_child_nodes\n",
    "                else (0, None)\n",
    "                for i in range(d_vars)\n",
    "                for j in range(d_vars)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    bnds = bnds_w + bnds_a\n",
    "    w_est, a_est = _learn_dynamic_structure(\n",
    "        X, Xlags, bnds, lambda_w, lambda_a, max_iter, h_tol\n",
    "    )\n",
    "\n",
    "    w_est[np.abs(w_est) < w_threshold] = 0\n",
    "    a_est[np.abs(a_est) < w_threshold] = 0\n",
    "    #sm = _matrices_to_structure_model(w_est, a_est)\n",
    "    #return sm\n",
    "    return w_est, a_est\n",
    "\n",
    "\n",
    "def _matrices_to_structure_model(\n",
    "    w_est: np.ndarray, a_est: np.ndarray\n",
    ") -> StructureModel:\n",
    "    \"\"\"\n",
    "    Converts the matrices output by dynotears (W and A) into a StructureModel\n",
    "    We use the following convention:\n",
    "    - {var}_lag{l} where l is the lag value (i.e. from how many previous timestamps the edge is coming\n",
    "    - if we deal with a intra_slice_node, `l == 0`\n",
    "    Args:\n",
    "        w_est: Intra-slice weight matrix\n",
    "        a_est: Inter-slice matrix\n",
    "    Returns:\n",
    "        StructureModel representing the structure learnt\n",
    "    \"\"\"\n",
    "    sm = StructureModel()\n",
    "    lag_cols = [\n",
    "        f\"{var}_lag{l_val}\"\n",
    "        for l_val in range(1 + (a_est.shape[0] // a_est.shape[1]))\n",
    "        for var in range(a_est.shape[1])\n",
    "    ]\n",
    "    sm.add_nodes_from(lag_cols)\n",
    "    sm.add_edges_from(\n",
    "        [\n",
    "            (lag_cols[i], lag_cols[j], dict(weight=w_est[i, j]))\n",
    "            for i in range(w_est.shape[0])\n",
    "            for j in range(w_est.shape[1])\n",
    "            if w_est[i, j] != 0\n",
    "        ]\n",
    "    )\n",
    "    sm.add_edges_from(\n",
    "        [\n",
    "            (lag_cols[i + w_est.shape[0]], lag_cols[j], dict(weight=a_est[i, j]))\n",
    "            for i in range(a_est.shape[0])\n",
    "            for j in range(a_est.shape[1])\n",
    "            if a_est[i, j] != 0\n",
    "        ]\n",
    "    )\n",
    "    return sm\n",
    "\n",
    "\n",
    "def _reshape_wa(\n",
    "    wa_vec: np.ndarray, d_vars: int, p_orders: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Helper function for `_learn_dynamic_structure`. Transform adjacency vector to matrix form\n",
    "    Args:\n",
    "        wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n",
    "        d_vars (int): number of variables in the model\n",
    "        p_orders (int): number of past indexes we to use\n",
    "    Returns:\n",
    "        intra- and inter-slice adjacency matrices\n",
    "    \"\"\"\n",
    "\n",
    "    w_tilde = wa_vec.reshape([2 * (p_orders + 1) * d_vars, d_vars])\n",
    "    w_plus = w_tilde[:d_vars, :]\n",
    "    w_minus = w_tilde[d_vars : 2 * d_vars, :]\n",
    "    w_mat = w_plus - w_minus\n",
    "    a_plus = (\n",
    "        w_tilde[2 * d_vars :]\n",
    "        .reshape(2 * p_orders, d_vars**2)[::2]\n",
    "        .reshape(d_vars * p_orders, d_vars)\n",
    "    )\n",
    "    a_minus = (\n",
    "        w_tilde[2 * d_vars :]\n",
    "        .reshape(2 * p_orders, d_vars**2)[1::2]\n",
    "        .reshape(d_vars * p_orders, d_vars)\n",
    "    )\n",
    "    a_mat = a_plus - a_minus\n",
    "    return w_mat, a_mat\n",
    "\n",
    "\n",
    "def _learn_dynamic_structure(\n",
    "    X: np.ndarray,\n",
    "    Xlags: np.ndarray,\n",
    "    bnds: List[Tuple[float, float]],\n",
    "    lambda_w: float = 0.1,\n",
    "    lambda_a: float = 0.1,\n",
    "    max_iter: int = 100,\n",
    "    h_tol: float = 1e-8,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Learn the graph structure of a Dynamic Bayesian Network describing conditional dependencies between data variables.\n",
    "    The optimisation is to minimise a score function F(W, A) over the graph's contemporaneous (intra-slice) weighted\n",
    "    adjacency matrix, W, and lagged (inter-slice) weighted adjacency matrix, A, subject to the a constraint function\n",
    "    h(W), where h_value(W) == 0 characterises an acyclic graph. h(W) > 0 is a continuous, differentiable function that\n",
    "    encapsulated how acyclic the graph is (less = more acyclic).\n",
    "    Based on \"DYNOTEARS: Structure Learning from Time-Series Data\".\n",
    "    https://arxiv.org/abs/2002.00498\n",
    "    @inproceedings{pamfil2020dynotears,\n",
    "        title={DYNOTEARS: Structure Learning from Time-Series Data},\n",
    "        author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer,\n",
    "        Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},\n",
    "        booktitle={International Conference on Artificial Intelligence and Statistics},\n",
    "        pages={1595--1605},\n",
    "        year={2020}year={2020},\n",
    "    }\n",
    "    Args:\n",
    "        X (np.ndarray): 2d input data, axis=1 is data columns, axis=0 is data rows. Each column represents one variable,\n",
    "        and each row represents x(m,t) i.e. the mth time series at time t.\n",
    "        Xlags (np.ndarray): shifted data of X with lag orders stacking horizontally. Xlags=[shift(X,1)|...|shift(X,p)]\n",
    "        bnds: Box constraints of L-BFGS-B to ban self-loops in W, enforce non-negativity of w_plus, w_minus, a_plus,\n",
    "        a_minus, and help with stationarity in A\n",
    "        lambda_w (float): l1 regularization parameter of intra-weights W\n",
    "        lambda_a (float): l1 regularization parameter of inter-weights A\n",
    "        max_iter (int): max number of dual ascent steps during optimisation\n",
    "        h_tol (float): exit if h(W) < h_tol (as opposed to strict definition of 0)\n",
    "    Returns:\n",
    "        W (np.ndarray): d x d estimated weighted adjacency matrix of intra slices\n",
    "        A (np.ndarray): d x pd estimated weighted adjacency matrix of inter slices\n",
    "    Raises:\n",
    "        ValueError: If X or Xlags does not contain data, or dimensions of X and Xlags do not conform\n",
    "    \"\"\"\n",
    "    if X.size == 0:\n",
    "        raise ValueError(\"Input data X is empty, cannot learn any structure\")\n",
    "    if Xlags.size == 0:\n",
    "        raise ValueError(\"Input data Xlags is empty, cannot learn any structure\")\n",
    "    if X.shape[0] != Xlags.shape[0]:\n",
    "        raise ValueError(\"Input data X and Xlags must have the same number of rows\")\n",
    "    if Xlags.shape[1] % X.shape[1] != 0:\n",
    "        raise ValueError(\n",
    "            \"Number of columns of Xlags must be a multiple of number of columns of X\"\n",
    "        )\n",
    "\n",
    "    n, d_vars = X.shape\n",
    "    p_orders = Xlags.shape[1] // d_vars\n",
    "\n",
    "    def _h(wa_vec: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Constraint function of the dynotears\n",
    "        Args:\n",
    "            wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n",
    "        Returns:\n",
    "            float: DAGness of the intra-slice adjacency matrix W (0 == DAG, >0 == cyclic)\n",
    "        \"\"\"\n",
    "\n",
    "        _w_mat, _ = _reshape_wa(wa_vec, d_vars, p_orders)\n",
    "        return np.trace(slin.expm(_w_mat * _w_mat)) - d_vars\n",
    "\n",
    "    def _func(wa_vec: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Objective function that the dynotears tries to minimise\n",
    "        Args:\n",
    "            wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n",
    "        Returns:\n",
    "            float: objective\n",
    "        \"\"\"\n",
    "\n",
    "        _w_mat, _a_mat = _reshape_wa(wa_vec, d_vars, p_orders)\n",
    "        loss = (\n",
    "            0.5\n",
    "            / n\n",
    "            * np.square(\n",
    "                np.linalg.norm(\n",
    "                    X.dot(np.eye(d_vars, d_vars) - _w_mat) - Xlags.dot(_a_mat), \"fro\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        _h_value = _h(wa_vec)\n",
    "        l1_penalty = lambda_w * (wa_vec[: 2 * d_vars**2].sum()) + lambda_a * (\n",
    "            wa_vec[2 * d_vars**2 :].sum()\n",
    "        )\n",
    "        return loss + 0.5 * rho * _h_value * _h_value + alpha * _h_value + l1_penalty\n",
    "\n",
    "    def _grad(wa_vec: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gradient function used to compute next step in dynotears\n",
    "        Args:\n",
    "            wa_vec (np.ndarray): current adjacency vector with intra- and inter-slice weights\n",
    "        Returns:\n",
    "            gradient vector\n",
    "        \"\"\"\n",
    "\n",
    "        _w_mat, _a_mat = _reshape_wa(wa_vec, d_vars, p_orders)\n",
    "        e_mat = slin.expm(_w_mat * _w_mat)\n",
    "        loss_grad_w = (\n",
    "            -1.0\n",
    "            / n\n",
    "            * (X.T.dot(X.dot(np.eye(d_vars, d_vars) - _w_mat) - Xlags.dot(_a_mat)))\n",
    "        )\n",
    "        obj_grad_w = (\n",
    "            loss_grad_w\n",
    "            + (rho * (np.trace(e_mat) - d_vars) + alpha) * e_mat.T * _w_mat * 2\n",
    "        )\n",
    "        obj_grad_a = (\n",
    "            -1.0\n",
    "            / n\n",
    "            * (Xlags.T.dot(X.dot(np.eye(d_vars, d_vars) - _w_mat) - Xlags.dot(_a_mat)))\n",
    "        )\n",
    "\n",
    "        grad_vec_w = np.append(\n",
    "            obj_grad_w, -obj_grad_w, axis=0\n",
    "        ).flatten() + lambda_w * np.ones(2 * d_vars**2)\n",
    "        grad_vec_a = obj_grad_a.reshape(p_orders, d_vars**2)\n",
    "        grad_vec_a = np.hstack(\n",
    "            (grad_vec_a, -grad_vec_a)\n",
    "        ).flatten() + lambda_a * np.ones(2 * p_orders * d_vars**2)\n",
    "        return np.append(grad_vec_w, grad_vec_a, axis=0)\n",
    "\n",
    "    # initialise matrix, weights and constraints\n",
    "    wa_est = np.zeros(2 * (p_orders + 1) * d_vars**2)\n",
    "    wa_new = np.zeros(2 * (p_orders + 1) * d_vars**2)\n",
    "    rho, alpha, h_value, h_new = 1.0, 0.0, np.inf, np.inf\n",
    "\n",
    "    for n_iter in range(max_iter):\n",
    "        while (rho < 1e20) and (h_new > 0.25 * h_value or h_new == np.inf):\n",
    "            wa_new = sopt.minimize(\n",
    "                _func, wa_est, method=\"L-BFGS-B\", jac=_grad, bounds=bnds\n",
    "            ).x\n",
    "            h_new = _h(wa_new)\n",
    "            if h_new > 0.25 * h_value:\n",
    "                rho *= 10\n",
    "\n",
    "        wa_est = wa_new\n",
    "        h_value = h_new\n",
    "        alpha += rho * h_value\n",
    "        if h_value <= h_tol:\n",
    "            break\n",
    "        if h_value > h_tol and n_iter == max_iter - 1:\n",
    "            warnings.warn(\"Failed to converge. Consider increasing max_iter.\")\n",
    "    return _reshape_wa(wa_est, d_vars, p_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fc8015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import scipy.linalg as slin\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import glob\n",
    "import re\n",
    "import math\n",
    "from torch.optim.adam import Adam\n",
    "from statistics import mean\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a21f8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_lsem_dynamic(W_all,Z: nx.DiGraph,\n",
    "                 n: int,n_time:int, treatment_type: str,\n",
    "                 noise_scale: float = 0.5,\n",
    "                 baseline: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Simulate samples from LSEM.\n",
    "        \n",
    "        Args:\n",
    "        W_all,A: weigthed DAG for instaneous relation and lagged relation\n",
    "        n: number of samples in each time-stamp\n",
    "        lag: degree of AR\n",
    "        n_time: number of time stamp\n",
    "        treatment_type: the type of the exposure {Binary, Gaussian}\n",
    "        noise_scale: noise scale parameter of Gaussian distribution in the lSEM\n",
    "        baseline: the baseline for the outcome\n",
    "        \n",
    "        Returns:\n",
    "        X: [time,n, d] sample matrix\n",
    "        \"\"\"\n",
    "    #W_array = nx.to_numpy_array(W)\n",
    "    Z_array = nx.to_numpy_array(Z)\n",
    "    d = Z_array.shape[0]\n",
    "    #X_all = np.zeros([n_time+1,n, d])\n",
    "    \n",
    "    ## create the initial data\n",
    "    X = np.zeros([n, d])\n",
    "    W_0=W_all[0,:,:]\n",
    "    ordered_vertices = list(nx.topological_sort(nx.from_numpy_matrix(W_0,create_using=nx.DiGraph)))\n",
    "    assert len(ordered_vertices) == d\n",
    "    rank_A = ordered_vertices.index(0)\n",
    "    for j in ordered_vertices:\n",
    "        if ordered_vertices.index(j) > rank_A:\n",
    "            parents = list(nx.from_numpy_matrix(W_0,create_using=nx.DiGraph).predecessors(j))\n",
    "            X[:, j] = X[:, parents].dot(W_0[parents, j]) + np.random.normal(scale=noise_scale, size=n)\n",
    "        elif ordered_vertices.index(j) < rank_A:\n",
    "            X[:, j] = np.random.normal(scale=noise_scale, size=n)\n",
    "        else:\n",
    "            if treatment_type == 'Binary':\n",
    "                X[:, j] = 2 * (np.random.binomial(1, 0.5, n) - 0.5)\n",
    "            elif treatment_type == 'Gaussian':\n",
    "                X[:, j] = np.random.normal(scale=noise_scale, size=n)\n",
    "            else:\n",
    "                raise ValueError('unknown exposure type')\n",
    "    X[:, d-1] += baseline\n",
    "    X_all=X\n",
    "    ## for follow-up time-stamps, X=XW+AZ+E\n",
    "    for time in range(1,n_time+1):\n",
    "        X_temp = np.matmul(X,Z_array)\n",
    "        W_array=W_all[time,:,:] ## different index!\n",
    "        W=nx.from_numpy_matrix(W_array,create_using=nx.DiGraph)\n",
    "        for j in ordered_vertices:\n",
    "            if ordered_vertices.index(j) > rank_A:\n",
    "                parents = list(W.predecessors(j))\n",
    "                X_temp[:, j] += X_temp[:, parents].dot(W_array[parents, j]) + np.random.normal(scale=noise_scale, size=n)\n",
    "            elif ordered_vertices.index(j) < rank_A:\n",
    "                X_temp[:, j] += np.random.normal(scale=noise_scale, size=n)\n",
    "            else:\n",
    "                if treatment_type == 'Binary':\n",
    "                    X_temp[:, j] += 2 * (np.random.binomial(1, 0.5, n) - 0.5)\n",
    "                elif treatment_type == 'Gaussian':\n",
    "                    X_temp[:, j] += np.random.normal(scale=noise_scale, size=n)\n",
    "                else:\n",
    "                    raise ValueError('unknown exposure type')\n",
    "        X_all=np.append(X_all,X_temp,axis=0)\n",
    "        X=X_temp\n",
    "    return X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "748f64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_all=np.zeros([11,5, 5])\n",
    "import math \n",
    "#def cos(x):\n",
    "#    return(-10+(5-x)**2)/20\n",
    "import math \n",
    "def cos(x):\n",
    "    return math.cos(x/4*math.pi)*0.8\n",
    "for i in range(11):\n",
    "    W_all[i,0,4]=cos(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b3db741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create Z matrix\n",
    "Z=np.zeros((5,5))\n",
    "#Z[0,0]=0 # no correlation for treatment\n",
    "Z_graph=nx.from_numpy_matrix(Z,create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b5564bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "p_orders=1\n",
    "d_vars=5\n",
    "n_var=5\n",
    "n_times=30 #no. of replicates\n",
    "time_stamp=10 #no. of timestamp\n",
    "np.random.seed(1234567) #Random seed\n",
    "seed_list=np.random.randint(1, 1000000, size=n_times)\n",
    "w_list=np.zeros((n_times,time_stamp,n_var, n_var))\n",
    "a_list=np.zeros((n_times,time_stamp,n_var, n_var))\n",
    "for replicate in range(n_times):\n",
    "  seed=seed_list[replicate]\n",
    "  X_all=simulate_lsem_dynamic(W_all,Z_graph,30,10, 'Binary',noise_scale=0.1)\n",
    "  for time in range(time_stamp):\n",
    "    X=X_all[(time+1)*30:(time+2)*30]\n",
    "    Y=X_all[(time)*30:(time+1)*30]\n",
    "    w,a=from_numpy_dynamic(X,Y)\n",
    "    w_list[replicate,time,:,:]=w\n",
    "    a_list[replicate,time,:,:]=a\n",
    "    #np.save(\"result/dynotears_quadratic_w_noA\",w_list)\n",
    "    #np.save(\"result/dynotears_quadratic_a_noA\",a_list)\n",
    "    np.save(\"result/dynotears_cos_w_noA\",w_list)\n",
    "    np.save(\"result/dynotears_cosa_noA\",a_list)\n",
    "  print(replicate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a06e5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dynotears=np.load(\"result/dynotears_quadratic_w_noA.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d484ef56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Causal strength')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXhU5dn48e892QkJgewLECBhCyQRIrKp7AokoNZXtLbuRau+bn1ta7Xazdb+bN1BRK2trRWXFkvYRBQUsKBBmbAGwiZhspGwhCxkmef3xxlCgCRMSCZnZvJ8rmuuzMw5M8/NkMx9nl2UUmiapmlaSyxmB6Bpmqa5N50oNE3TtFbpRKFpmqa1SicKTdM0rVU6UWiapmmt8jU7AFeIiIhQiYmJZoehaZrmMTZv3nxEKRXZ3DGvTBSJiYnk5OSYHYamaZrHEJGDLR3TTU+apmlaq3Si0DRN01qlE4WmaZrWKq/so9AuXl1dHQUFBdTU1Jgdiqa1SWBgIAkJCfj5+ZkditcxLVGISG/gbSAGsAMLlVIvnnOOAC8CM4Aq4Dal1DedHWtXUlBQQEhICImJiRgfv6a5P6UUZWVlFBQU0K9fP7PD8TpmNj3VAz9RSg0BRgP3icjQc86ZDiQ7bnOBVzs3xK6npqaG8PBwnSQ0jyIihIeH65qwi5iWKJRShadrB0qpCmAnEH/OabOBt5VhIxAmIrGdHGqXo5OE5on0763ruEVntogkApcAm845FA8cavK4gPOTyen3mCsiOSKSU1pa6oowNU3TznO8uo7F3xZgt3vvlg2mJwoR6Q78C3hIKXXi3MPNvKTZ/w2l1EKlVIZSKiMystnJhRdUUlFDyQlddTWbj48P6enppKSkkJaWxnPPPYfdbqekpIR+/fpRVFTUeO69997LM888w9q1axERsrOzG49lZmaydu1aAGpra3nooYcYMGAAycnJzJ49m4KCAsrKykhPTyc9PZ2YmBji4+MbH9fW1jbGcvr2zDPPNL5/aWkpfn5+vPbaa2fFn5iYyPDhw0lNTeXKK6/k4MEz85iefvppUlJSSE1NJT09nU2bNnHttdeSnp5OUlISPXr0aCzryy+/dNEn3D7V1dVMmjSJ9PR0PvzwQ9auXUtKSgqXXHIJBw8eZM6cOa2+/vbbbycvL++iyv7ss8/YuHHjRb3WVeatyefh96y8sHq32aG4jlLKtBvgB3wMPNLC8deAm5o8zgNiL/S+I0eOVG1VeapODXx8ufrd0u1tfq032bFjh9khqODg4Mb7xcXFavLkyerJJ59USin16quvqptvvlkppdTmzZvV8OHDVW1trVqzZo1KSEhQl112WeNrZ86cqdasWaOUUuonP/mJuuOOO1R9fb1SSqm//OUv6tJLL1V2u73x/Keeeko9++yzLcZyrnnz5qnx48erK6+88qzn+/btq0pLS5VSSj355JPqrrvuUkop9eWXX6rRo0ermpoapZRSpaWl6vDhw42vW7NmjZo5c2aL5dXV1bV4rDOtW7dOTZo0qfHxnXfeqd5+++1WXtFxHn/8cfX888+3eLyzf38bGuxqzO9Xq+RfLFd9f7ZUrdxW2KnldyQgR7XwnWpajcIxoulNYKdS6rkWTlsC3CKG0cBxpVShK+Lp5u/L5ckRLM0t9OoqpKeJiopi4cKFvPLKKyilmDt3Lnv37mXNmjXcf//9vPLKK43DIdPS0ujRoweffPLJWe9RVVXFW2+9xfPPP4+Pjw9gXNUGBATw2WefXXRs7777Ln/+858pKCjg8OHDzZ4zZsyYxmOFhYVEREQQEBAAQEREBHFxca2WkZCQwG9/+1vGjRvH4sWLGT9+PFu2bAGgqKiIpKQkAOrr63nkkUcYNWoUqampvPHGG82+31tvvUVqaippaWncfvvtAOzfv5+JEyeSmprK1KlTKSgoAKC4uJjrrruOjIwMRo0axcaNG7HZbNx2223k5OSQnp7OggUL+Pe//82TTz7JLbfcQn5+Punp6Y0xPfzwwwwbNozU1FTmz58PcNa/YcWKFYwZM4YRI0YwZ84cKisrG//dv/rVr7jkkktITU1l9+7d7N27lzfeeINnn33WbWpc33x3FNvxGn57TQppCT145L0t5JdUmB1WhzNzHsU44IfAVhHZ4njuF0AfAKXUAmA5xtDYfIzhsbe7MqCstDhW7ywh5+BRRvXr5cqiPMKvs7ezw3Zua2D7DI0L5amslDa9pn///o1NT9HR0bz66qtMmjSJWbNmccUVV5x17hNPPMETTzzB1KlTG5/Lz8+nT58+hIaGnnVuRkYG27dvZ/LkyS2WXV1d3fjFB/DYY48xZ84cDh06RFFREaNGjeKGG27gvffe45FHHjnv9StXruSaa64BYNq0afzmN79h4MCBTJkyhTlz5nDllVde8N8fHBzMhg0bAHjxxRebPWfhwoVERUXx1VdfcerUKUaPHs20adPo06dP4zlWq5U//vGPfPnll/Tq1Yvy8nLAaL676667uPnmm1m4cCEPPfQQH374IQ888AA//elPGT16NAcOHCAzM5Nt27axYMECXnnlFT766CMA1q9fz/XXX88111xDfn5+Y3mvvvoqNpsNq9WKj49PY3mnlZSU8Mwzz/Dpp5/SrVs3nn76aV588UV+8YtfABAdHc23337LSy+9xHPPPceCBQu46667iIiI4KGHHrrg59YZsq02AnwtzEyN44qBkWS9vJ65b2/mo/vHERroPfM5TEsUSqn1NN8H0fQcBdzXORHB1KHRBPn5sMR6WCcKN6Oa7O2enp7OsGHDuPfee8877/LLLwdg3bp1Z722uRExLT3fVFBQUOPVb1OLFi3ihhtuAODGG2/kzjvvPCtRTJw4keLiYqKiovjd734HQPfu3dm8eTPr1q1jzZo1zJkzh2eeeYbbbrut1Rgu1OYPsGrVKnbu3MmiRYsAOH78OHv27DkrUXz22WfMmTOHXr2M3+3TPzdt2sTSpUsBuOWWW/jlL38JwOrVq8/qSzh69CjV1dUXjOW01atX89BDDzXW4k6Xd9qXX37Jjh07GDt2LGD0I40fP77x+HXXXQfAyJEjWb58udPldpb6BjvLthYyeUgU3QN86R7gy7zvj+DmNzbx8KItvH5LBhaLd4zE0jOzm+jm78vkIVEs31rEU1kp+PmY3tdvqrZe+bvKvn378PHxISoqqvE5i8WCxdL8/8/jjz/O008/ja+v8eudlJTEwYMHqaioICQkpPG8b775hqysrIuK6d1336W4uJh33nkHAJvNxp49e0hOTgZgzZo1BAcHc9ttt/Hkk0/y3HNG66qPjw8TJkxgwoQJDB8+nL/97W8XTBTBwcGN9319fbHb7QBnzRlQSjF//vxWa0fOJMZzz//qq6/w9/d3+jVtKU8pxdVXX83f//73Zo+fbqLz8fGhvr7+omJwpU37yzlyspas1DPNh5f1D+eXmUN5asl2Xvh0D49MHWhihB2na38TNmNWWhzllbVsyD9idigaxsiie+65h/vvv9/pL7lp06Zx9OhRrFYrYHzR3nrrrTzyyCM0NDQA8Pbbb1NVVcWkSZPaHFNeXh6VlZUcPnyYAwcOcODAAR577LHGq/nTgoKCeOGFF3j77bcpLy8nLy+PPXv2NB7fsmULffv2bVPZiYmJbN68GYAPP/yw8fmrrrqK+fPnN36h5uXlnXf1P2XKFBYtWtTYBHT65+jRo3n//fcB+Mc//tHYnDdlyhTmzZt3VrxtMW3aNF599dXGz/zcpqexY8fy+eefs2/fPgAqKyvP+nyaExISQkWFe/QBZFttBPv7MHFw1FnP3zKmL9ePTOClT/fw8faiFl7tWXSiOMeVgyIJDfRlidVmdihd1ul+gZSUFKZMmcK0adN46qmn2vQejz/+eGOnLMAf/vAHAgMDGThwIMnJyXzwwQcsXrz4gsnndCynbz//+c959913ufbaa88673vf+x7vvvvuea+PjY3lpptuYt68eZw8eZJbb72VoUOHkpqayo4dO/jVr37Vpn/Xo48+yosvvsjYsWM5evRo4/N33303ycnJjc1yP/7xj8+7Ck9NTeWnP/0pV1xxBenp6Tz66KMAvPLKKyxcuJDU1FTee+89nn/+eQDmzZvHhg0bSE1NZejQobz++uttivXuu+8mJiamsfP8dDI6LTo6mjfffJM5c+aQlpbG2LFj2b279SGms2fP5v333+eSSy4xtTO7tt7Oim1FTEuJIdDP56xjIsLvrhlGqhd1bkvTtl9vkZGRodqzcdFPP7SyfGsROU9MOe+XwNvt3LmTIUOGmB2Gpl2Uzvr9/WxXMXf8NYc3b81g8pDoZs+xHatm1ivrCQ3084jObRHZrJTKaO6YrlE0Y1ZaPCdP1bM2r8TsUDRNc0PZ1kJCA325PLnlyb1xYUHM+/4Iviuv4uFFWzx62L1OFM0YMyCciO4BuvlJ07Tz1NQ1sGp7EdOHxeLv2/pX6OnO7U93lfDCp633v7gznSia4WMRMlNj+XRnCRU1dWaH0+m8sTlS836d9Xu7ZlcJlbUNZKW1PlnytKad26s8tHNbJ4oWZKXFcqrezic7is0OpVMFBgZSVlamk4XmUZRjP4rAwECXl7U0t5CI7v6M7u/cXKuzOrfft5JfctLFEXY8PY+iBSP69CQ+LIglVhvXjUgwO5xOk5CQQEFBAXoFXs3TnN7hzpVOnqrn013F3JDRG982zLMK9PNhwQ9GMuuV9cx9O8cjOreb0omiBSJCVlocb6zbR3llLb2CL27Skafx8/PTO4RpWgs+3VlMTZ3d6Wanpk53bnvizG3d9NSKWWlx1NsVy7e6ZB1CTdM8TLbVRmyPQEb26XlRr7+sfzhPzBzCp7tKeNGDOrd1omjFkNgQkqK6k61HP2lal3e8qo7Pd5eSmRrbrprArWMT+d6IBF70oM5tnShaISLMSovjqwPlFB3XGxppWlf28fYi6hrURTU7NSUiPH2tZ3Vu60RxAVlpcSgFS3N1rULTurLsXBt9w7sxPL5Hu9/rdOd2gK+FuX/P4YSbD8PXieIC+kUEMzy+h558p2ld2JGTp9iQf4TM1Ng2rcDbmriwIObdPILvyqp45D33nrmtE4UTZqXFkVtwnP1HKs0ORdM0E6zYWohd0e5mp3ONdnRur97p3p3bpiYKEfmLiJSIyLYWjk8QkeMissVxe7KzYwTITItFBN2prWldVLa1kOSo7gyKDrnwyW3kCZ3bZtco/gpcfYFz1iml0h2333RCTOeJ7RHEpYm9WGK16RnLmtbFFB6v5qsD5WSlxXVYs1NTpzu3h8e7b+e2qYlCKfUFUH7BE93ArLQ48ktOsrPQ89eW1zTNectyjXlUmamxLisj0M+H137ovp3bZtconDFGRKwiskJEWtybU0TmikiOiOS4YvmJGcNj8bEI2Xr0k6Z1Kdm5hQyLD6V/ZHeXluPOndvunii+AfoqpdKAl4GPWjpRKbVQKZWhlMqIjGx5jfiL1SvYn/FJEWTr5idN6zK+K6vCeujYWftiu1LTzu2XPnOfzm23ThRKqRNKqZOO+8sBPxGJMCueWWlxFByt5pvvjpkVgqZpneh0C8JMFzY7nevWsYlcNyKeF1bvcZvVq906UYhIjDh6j0RkFEa8ZWbFMy0lmgBfix79pGldRLbVxsi+PUno2a3TyhQRfn/tcIbH9+Dh97a4Ree22cNj3wX+CwwSkQIRuVNE7hGRexynXA9sExEr8BJwozKx3Sck0I9Jg6NYmltIfYPdrDA0TesEe4or2FVUQVYn1iZOc7fObbNHPd2klIpVSvkppRKUUm8qpRYopRY4jr+ilEpRSqUppUYrpb40M14wmp+OnDzFxn0eMVhL07SLlJ1biEVghgmJAozO7Ve+P4KDZVU88p7V1M5tt256ckcTB0fRPcCXJdbDZoeiaZqLKKVYarUxun84USGu3zWvJWMGnO7cLja1c1snijYK9PNhWko0K7cVcaq+wexwNE1zge22E+w7UklmJ412as1tbtC5rRPFRchKi+NETT1f7D5idiiaprlAdq4NX4tw9bAYs0Nxi85tnSguwvikCHp289MrymqaFzKanQoZnxzhNlsgB/r5sMDRuX3333Oo6OTObZ0oLoKfj4UZw2NZvaOYqtp6s8PRNK0DfXvoGIePVXfaJDtnxTs6tw+UVfFwJ3du60RxkWalxVFd1+A2E2I0TesY2VYb/r4WpqZEmx3KeZp2br/8WX6nlasTxUW6NLEXsT0C9eQ7TfMiDXbFstxCJg6KJDTQz+xwmnW6c/v51btZ3UkXqjpRXCSLRchMjeXz3aUcq6o1OxxN0zrAV/vLKak41eEbFHWkczu395a6vnNbJ4p2mJUWT12D4mM33WxE07S2yc610c3fh0mDo8wOpVWnO7f9fS3Mfdv1nds6UbTDsPhQEsO76dFPmuYF6hrsrNhayJQh0XTz9zU7nAtq2rn9yPuu7dzWiaIdRIRZaXH8d28ZJRU1ZoejaVo7bMg/wtGqOrdudjrXmAHhPD5jCJ/scG3ntk4U7TQrPQ67OrMLlqZpninbWkhIoC9XDDRtJ4OLcvs413du60TRTklRIQyJDdXNT5rmwWrqGli1vYirUmII8PUxO5w2adq5/eiHVipPdfzcLvdviPMAs9Li+OPKXRwqr6J3r85bt17TtI7x+e5SKk7Ve1SzU1OnO7cPH60mOKDjv9Z1jaIDZKUZyxDrWoWmeaZsq41ewf6MHRBudigXLT4siFH9ernkvXWi6AAJPbsxsm9PPflO0zxQVW09n+4sYfqwGPx89Fdic8ze4e4vIlIiIttaOC4i8pKI5ItIroiM6OwYnZWVGsuuogp2F1eYHYqmaW3w6c4SqusaPLbZqTOYnT7/ClzdyvHpQLLjNhd4tRNiuigzU+OwCLpWoWkeJttqIzo0gEsTXdNs4w3M3gr1C6C1PUVnA28rw0YgTETM2ZfwAiJDAhg7IIIlVhsmbuutaVobnKipY21eKTOHx+FjEbPDcVtm1yguJB441ORxgeO584jIXBHJEZGc0tLSTgnuXLPS4jhYVkVuwXFTytc0rW1WbS+mtsHeOCBFa567J4rmUnyzl+tKqYVKqQylVEZkZKSLw2reVcNi8Pex6NFPmuYhsq02EnoGkd47zOxQ3Jq7J4oCoHeTxwmA234L9wjy48pBkSzNtdHQiZuKaJrWduWVtazPP0JWWhwiutmpNe6eKJYAtzhGP40Gjiul3HqtjFlpcRSfOMVX+1vretE0zWwrthXSYFdut5OdOzJ1ZraIvAtMACJEpAB4CvADUEotAJYDM4B8oAq43ZxInTd5SBRBfj5k59oY48GTdzTN22VbbQyIDGZIbIjZobg9UxOFUuqmCxxXwH2dFE6H6Obvy9Sh0azYWsivZ6XoCTya5oaKT9SwaX85D0xK1s1OTtDfYi4wKy2Oo1V1rN9zxOxQNE1rxrLcQpRCj3Zykk4ULnDFwEh6BPnp0U+a5qaW5toYEhtKUpRudnKGThQu4O9rYfqwGFZtL6K6tsHscDRNa+JQeRXffHdM1ybaQCcKF5mVFkdlbQOf7SoxOxRN05pYttUYOKlHOzlPJwoXuax/OJEhASyxHjY7FE3Tmsi22kjvHab3jmkDnShcxMcizBwey5q8Uk7U1JkdjqZpwN7Sk2y3nfDOlWKrymHfWpe8tVOJQkTiRWSsiFxx+uaSaLzMrPQ4auvtrNrumn1sNU1rm6XWQkRg5nAv65/Y8R+YNwo+uA1qKzv87S84j0JE/gjMAXYAp3tmFfBFh0fjZS7pHUbvXkEssdq4fmSC2eFoWpemlGKJ9TCjEnsR0yPQ7HA6xslSWP5/sOMjiE2D2fPBP7jDi3Fmwt01wCCl1KkOL93LiQhZqXG89sU+yk6eIrx7gNkhaVqXtauogr2lldw+rp/ZobSfUrD937D8UThVAZN+CeMeBB8/lxTnTNPTPhzLamhtNys9jga7YvlWt16iStO8XrbVho9FmD4sxuxQ2qeiGN77AXx4B4T1hbu/gCv+z2VJAlqpUYjIyxhNTFXAFhH5FGisVSilHnBZVF5kcEwoA6O7s8Rq44djEs0OR9O6JKUU2bk2xg4I99yavVKQ+z6s/BnUVsGUX8OY+8HH9SsxtVZCjuPnZoxVXJvSa2i3way0OP60ajeHj1UTHxZkdjia1uVYC45zqLya/52UbHYoF+dEISx9CHavhIRRMHseRA7stOJbbHpSSv1NKfU3IOz0/SbP9ey0CL1ApmNiz7JcvaSHpplhqdWGn49wVYqHNTspBd/+A+ZdBvs+h6t+D3es7NQkAc71UdzazHO3dXAcXi0xIpi0hB567SdNM4HdrliaW8iVA6PoEeRB3a3HC+Cd6+E/90F0Cvx4A4y5Dyw+nR5Ka30UNwHfB/qJSNOmpxCgzNWBeZustDh+t2wn+0pP0j+yu9nhaFqXkXPwKEUnanhsxmCzQ3GOUvDN3+DjJ0A1wPRn4dK7wGLe/OjW+ii+BAqBCODPTZ6vAHJdGZQ3ykqL4+nlO1litfHQlM6tNmpaV5ZttRHoZ2HKkGizQ7mwowch+wFjhnXi5TDrZehl/nDe1vooDiql1iqlxiilPm9y+0YpVd8RhYvI1SKSJyL5IvLzZo5PEJHjIrLFcXuyI8o1Q3RoIJf168USqw1jPyZN01ytvsHO8q2FTB4STXCAqfu0tc5uh69eh1fHQkEOzHwOblniFkkCnJuZXcH5o5yOY4yK+olSat/FFCwiPsA8YCpQAHwtIkuUUjvOOXWdUirzYspwN7PS4vnF4q1st51gWHwPs8PRNK/3331llFXWuvdKseX7YMkDcGAd9J8Is16CsD5mR3UWZxq9ngMeBeKBBOD/gNeBRcBf2lH2KCBfKbVPKVXreL/Z7Xg/tzd9WAy+FiFbd2prWqfIttroHuDLhEGRZodyPrsdNi6AV8dBoRWyXoIfLna7JAHOJYqrlVKvKaUqlFInlFILgRlKqfdo3zDZeOBQk8cFjufONUZErCKyQkRSWnozEZkrIjkiklNaWtqOsFynZ7A/lydHkG21Ybfr5idNc6VT9Q2s3FbEtJRoAv06f6RQq8r2wl9nGJPn+o6DezfCyFvBTffvdiZR2EXkBhGxOG43NDnWnm+75j6Rc9/vG6CvUioNeBn4qKU3U0otVEplKKUyIiPd8OrBYVZ6HLbjNXzz3VGzQ9E0r7Zu9xFO1NS715Li9gb48mWjL6JkB1zzKtz8AfRo7hrZfTiTKG4GfgiUAMWO+z8QkSDg/naUXQD0bvI4ATirTcZRgznpuL8c8BORiHaUabqpQ2MI8LXoORWa5mLZuTbCuvkxPslNvjJK8+AvV8GqJ2DAJLh3E6R/321rEU1dMFE4+hCylFIRSqlIx/18pVS1Ump9O8r+GkgWkX4i4g/cyDlLhYhIjIjxKYrIKEe8Hj2Ho3uAL1OGRLN8ayH1DXazw9E0r1Rd28AnO4qZPiwGPx+T92drqId1z8GCy6EsH657A278J4R6zp4Yzox6igR+BCQ2PV8pdUd7ClZK1YvI/cDHgA/wF6XUdhG5x3F8AXA98GMRqQeqgRuVF4wtzUqLY9nWQr7cW8YVA923mUzTPNWavBKqahvMH+1UvAP+cy/YvoUhWcaw1+5R5sZ0EZwZWPwfYB2wmjMbF3UIR3PS8nOeW9Dk/ivAKx1ZpjuYMCiSkABfllhtOlFomgtkW21EdA/gsv7h5gTQUAfrX4DP/wiBoXD9W5ByrUc0MzXHmUTRTSn1M5dH0oUE+vlw1bAYPt5WxO+uGeZ+IzI0zYNV1NTx2a4SbhrVBx+LCV/MRVvho3uhKBdSroMZz0Kwm/STXCRnGu+WisgMl0fSxWSlxVFxqp61ee45lFfTPNXqncWcqreTldbJfQD1tbDmD7BwAlQUwZx/wP+85fFJApxLFA9iJIsaETkhIhUicsLVgZnCBZuSt2TcgHDCg/3J1kuPa1qHyrYWEh8WxCW9O3E3BNu38PpE+PwZGPY9uG+T0SfhJS7Y9KSUCumMQEzXUGfMkIy7BCY85vL13n19LMwYHssHmw9Rearevdeh0TQPcayqli92l3Ln+H5YOqPZ6YQNvvgTbP6r0Ul90yIYNN315XayC9YoxPADEfml43Fvx1BV79JQB8Oug90fw/zLYPE9UL7fpUXOSo+jps7OJzuKXVqOpnUVK7cVUW9Xrp9kd7IEVj4GL6bDN29Dxu1w73+9MkmAc01P84ExGHtTAJzEWMzPu/h3g8lPwkO5MPpe2L4YXskwFus6dujCr78II/v0JK5HoJ58p2kdJDvXRr+IYFLiQl1TQFU5fPIUvJgGm16D1BvgfzfDzD9DkPdu/OlMe8dlSqkRIvItgFLqqGOCnHcKjoCrnjY2LV//HOS8BdZ3YeRtcPlPIKTjtlK0WISstDjeXL+fo5W19Az23o9V01ytpKKG/+4t4/6JSUhHD0OtPgYb58N/50PtSSNBXPkzCB/QseW4KWdqFHWOJcEVNE7A8/4pxaGxxrC2B76FtJvg6zeNq4hVT0DlkQ4rJistjnq7YsW2og57T03rilZsLcKu6Nhmp1MnjT6IF1ONORFJk40F/K5b2GWSBDiXKF4CFgNRIvI0sB74vUujcidhvY314f83x5gw89958EIqfPpbqG7/wn4pcaH0jwhmifVwBwSraV1XttXGoOgQkqM7YPxNbZWxeN+LqfDZb6HPWLh7HdzwN4jykC1VO5Azaz29A/wU+APG1qjXKKU+cHVgbqdXf7h2gbGQ18CrYN2f4IU0+Pz/Qc3FjxYWMZqfNu0vp/hETQcGrGldh+1YNTkHj7Z/7kT9Kdi0EF5KN1oPYtPgrs/g+4sgNrVjgvVArSYKx7Li25RSu5RS85RSryildnZWcG4pcqAxieaeDZA4HtY8bVx1rH/houdhzEqPQylYmlvYwcFqWtewzPG3k3mxazs11BlDXF8aASsehfAkuH2FsZFQwsiOC9RDtZoolFJ2wCoi7rflktlihsFN/4QffQbxI2G1YyTExlehrm01gwGR3UmJC9WjnzTtImXn2khN6EFiRHDbXmhvgC3vGiMcsx80+iZ/+BHctgz6jnVNsLdoiokAACAASURBVB7ImT6KWGC7iHwqIktO31wdmMeIHwk/+Bfc8TFEDoaVP4eXLjE6v+trnX6bWWlxWA8d42BZ580O1zRvcOBIJbkFx9u2UqzdDtv+BfNHw0f3QEAofP99uPMTGDDRYxfvcxVnhsf+2uVReIM+o+G2pbDvc6M5atkjsOEFYwhd6o3g0/pHnZkWxx9W7CLbauP+ScmdFLSmeb6ljmVwZqY60T+hFOxaBmt+DyXbIXKIsSbT4EydHFrhTI1ihlLq86Y3QC8S2JL+Vxq1i5v/BUG94D/3wbxRkPuBUc1tQXxYEJcm9tTNT5rWRtnWQi5N7ElcWFDLJykFez4x1mN672ZoOAXfexN+vMFYk0kniVY5kyimNvOcd85T7ygikDwF5q41drLyDYR/32Xsk7vjP0a1txlZaXHsLj7JriLvXHNR0zpaXlEFecUVrc+d2P+FsQXpO9dDVRnMnm+MXhx+PVj0Ev/OaDFRiMiPRWQrMFhEcpvc9gO5HVG4iFwtInkiki8iP2/muIjIS47juSIyoiPK7TQiMHgm3LMerv8LKDu8fwssvBLyVhpXOU3MGB6Lj0XI1rUKTXPK0lwbFoHpw5ppdvpuI/w1E/6WZSzDk/k83L8ZLrn5gk3B2tlaq1H8E8jC2OEuq8ltpFLqB+0t2DHbex5G7WQocJOIDD3ntOlAsuM2F3i1veWawmIxlh6+dyNc+xqcOgHvzoE3psDezxoTRkT3AMYOCCfbWogX7PiqaS6llCLbamPsgAgiQwLOHDj8Dfzje0YtojQPrv6jscJCxh3gq5fJuRgtJgql1HGl1AHgCaBIKXUQ6Af8QETCOqDsUUC+UmqfUqoWWATMPuec2cDbyrARCBMRz9mR/FwWH0i7Ee7PgayXjM1N/n4t/HUmHNgAGKOfviuvYsuhYyYHq2nubdvhExwoqyLzdCd20TZ49/tGP8Thb2Dqb+DBLTD6HvALNDdYD+dMH8W/gAYRSQLexEgW/+yAsuOBpsuyFjiea+s5AIjIXBHJEZGc0lI33zXOxw9G3goPfAPTn4WyfPjrDHj7Gmb0Ooy/j4Vsq558p2mtyc614ecjzIg9AR/cBgvGwYH1MPFxeNAK4x4E/zbOq9Ca5UyisCul6oHrgBeUUg9jzK1or+aGGZzb3uLMOcaTSi1USmUopTIiIyPbHVyn8A2Ay+bCA1tg2u+gKJfgt6/igx4vUGpdgb2+3uwINc0t2Rvs7P92DW+HvUnoXy43RjRd/n/wkBWu/CkEumiZ8S7KmR6dOhG5CbgFo48CwK8Dyi4Aejd5nACc24vrzDmez78bjP1fYynzTa8xZN1LvFy/kdo/v4b/iBuNeRjR53bfaFoXdPQA5L5Pbc47vF53gHp7EIy5D8Y95BV7U7srZ2oUt2NsXPS0Umq/iPQD/tEBZX8NJItIP8f+FjcC5874XgLc4hj9NBo4rpTy3jaZgBC44v+oe2gHDzY8xF6/JGO12lfHwGtXGMuDnHTzZjVN62g1x41d5N6aYSyTs+b3HFbh/Nz+Y049uNOojesk4VLO7Jm9A3igyeP9wDPtLVgpVS8i9wMfAz7AX5RS20XkHsfxBcByjMl9+UAVRtLyesHB3akfMpsf7B3PpodS8d2xGHIXGcuDfPw4JE0xOsUHzdCddJp3aqg3RgTmLjJmUtfXQHgyTH6S+pTruWHebkYPDic41Ht3lXMnpg4mVkotx0gGTZ9b0OS+Au7r7LjcQVZqHMtyC/lvsYXLR99jjNwo2WX84Vjfgz0fQ0APSLnG2Fipz2g9u1TzfIW5YF0EWz+AyhJjdYMRtxgXRnEjQIQvd5dSVlnbtrWdtHbRs07c1IRBkXQP8GWptZDLkx2d81GDYcqvYNIv4cA6xx/Uh/DN36BnotGXkTbH2DtD0zzFiUIjMVgXGesvWfxg0NXGBVDS1PPmPmRbbYQE+DJhkIcMWvECOlG4qUA/H6YNjWbFtkJ+e80w/H2bdCdZfKD/BOM240+wa6mxr/fnf4TPn4Heo40rsJRrIagjprxoWgerrTKalKzvwr41xqoFCZfCzD9DynXQrVezLztV38DK7UVMS4kh0E8vv9FZWkwUIpJNC0NRAZRSs1wSkdYoMy2Wf397mPX5pUwaHN38SQHdjaSQdiMcPwxb3zfW11/6EKz4GQya7rgym2zM39A0s9jtcHCDUXPY8R+orYAefeDynxi14YikC77F53mlVNTUMytdNzt1ptZqFH/qtCi0Zo1PiqRHkB/Z1sKWE0VTPeJh/MPGUMHCLWfaend8BN0iYPj/GAklNk33Z2id58ge43cx9z04fgj8QyBltqNvbayxxI2Tllht9Ar2Z+yAcBcGrJ2rxUThWE5cM5G/r4WrU2JYmmujpq7B+aq2CMRdYtym/Q7yVxtV/Jw3YdOrxhr8aTdC6g0Qqq/MNBeoKjc2BrIugsM5IBYYMMnoYxs0w5g71EaVp+pZvbOY60cm4OfjfHLR2u+CfRQikgz8AWPhvsaxmEop3WPaCbLS4ngv5xBr80q4urkVMi/Ex89ofho0HaqPwvbFxh/v6qdg9a+Mfo60m2BIpl7uQGuf+lrYs8q4KNn9MdjrICrFuFgZ/j8QEtOut1+9s5iaOrse7WQCZzqz3wKeAp4HJmLMZdDtFp1kdP9ehAf7k20tvLhE0VRQT2MFzYw7oGyv0RRgfRcWz4WlwTB0tjFqKvFyvU6/5hyljAX4rO/Ctg+Ni5HgKLjsbqPWGjO8w4rKttqICQ3k0sTmO7o113EmUQQppT4VEXGsIPsrEVmHkTw0F/P1sTBjeCwfbD5E5al6ggM6aKBa+ACY+Au48udwaKPxh779I7D+E0LjjWap1DnGPuC6P0M719EDxtBs6yIo22NszjV4plE77T+xw/d7OF5Vx+e7S7l1TCIWi/597GzO/G/WiIgF2OOYSX0YiHJtWFpTWWlx/H3jQVbvLGZ2erOL5148iwX6jjVu0/8f5C03/vg3vATrn4du4cawxdO3+BHGUiNa11FXYwyOKPjauB36GiocS671HQfjHjBqo4E9XBbCyu2F1DUoPdrJJM4kioeAbhjLePwWmATc6sqgtLNl9O1JTGggS3MLOz5RNOUXZGywNOx7cLLESBqHvoaCr2D3SuMcsUDUUEjIcCSPURCe1KaRK5obUwqOHYSCHDj0lZEYirYa/Q0AYX0hcRzEZxiT4nomdkpY2dZC+oZ3Y3i865KR1jJn1nr62nH3pIjcCXRXSulNnTuRxSLMTI3l7/89yPHqOnoEdcJ8iO5Rxmq2I28zHlcfhcObHYnja6NTfPNfjWOBPYwvjt6jjAQSP9LoD9HcX22l0cdQ8LWRHAq+NpbOAPDrZvxfjr3fuCBIyDB+LzpZSUUNX+49wn0TkxDdDGoKZ0Y9/RO4B2gANgM9ROQ5pdSzrg5OOyMzNZY31+9n1fYi/iej94Vf0NGCehqLESZNMR7b7UbbdNPmiLXP0DhHM2KQUePo7WiyihysO8jNppQxiKHAUUss+BqKd4BqMI6HJxkTM083M0YNdYu9pVdsLcKujCZYzRzO/BYMVUqdEJGbMRbw+xlGwtCJohOl9w4joWcQS3MLzUkU57JYIHKQcbvEsYV6zQmwNbk6zVsOWxwr0vuHGP0bTfs7gvWkKZeqOd6ktuC4VR81jvmHQMJIY1Z0wqVGbaGFZTPMtsRqY3BMCAOjdd+YWZxJFH4i4gdcA7yilKoTkRaX9tBcQ0TITI3j9XX7KK+spVewG24SHxh6Zg0qMK5gy/c5mjQcV7Drnz9zBdur/9mJIzpFLzNysex2OJJ3dg2vdBdGDU+MGt3gTEctbxREDPSIGl7B0So2HzzKo1cNMjuULs2ZRPEacACwAl+ISF9A91GYICstlgWf72XltiK+f1kfs8O5MBFjGG74AGN+BhiLwdm+PfOFtm+tMZ8DwDfIUeto0lEe4sTSJV1RVbmjz8iRgA9vhlOOP8vAMOPzG3bdmT4jF45IcqWlucY+ZXqSnbmc6cx+CXipyVMHRWRiewoVkV7Ae0AiRhK6QSl1tJnzDgAVGP0j9UqpjPaU6+mGxobSPyKYbKvNMxJFc/y7GaNmEscZj5Uy1v859NWZztT/zj8zyqZHH4hNNYbpBvU0mkeCep352fhcT8+vjdgboPoYVJcbiaC63GgqOn2/qhyqyqBkB5TlG68RizH7efj1TUahDfCauS/ZVhtpvcPoE972JT+0juNMZ/aTLRz6TTvK/TnwqVLqGRH5uePxz1o4d6JS6kg7yvIaIkJmWhwvf7aHkhM1RIV6we52IhDWx7gNv954rq4GinIdTShfGU0oh74yvizt9S2/V0Do2YmjaUI567kmxwJCO/5LVSmoPdnMl/3RlhNAdbnRp9Di5+Rz5t8Wngzp3zeSQtwlxgrCXmhv6Um2207wy0y9X7zZnGl6qmxyPxDIBHa2s9zZwATH/b8Ba2k5UWhNZKXG8tKne1i+tZDbxvUzOxzX8As02tF7j4IxTTY4PPcL+PSX73lfukeN++X72/YFfFZCaeY58Tm/jJYSwOkaUXNOJ7TTZfTs10wNqUlCC+ppNB15SS3BWdlWGyLGiD/NXM40Pf256WMR+ROwpJ3lRiulCh3vXygiLQ3OVsAqR+f5a0qphe0s1+MlR4cwOCaEpblenChaImLMCg8IgZ59nX9dQ72RLJpevZ/3Ze/4eewQFFqN+/XVrb+vj//ZtZaI5Ga+7L2wiawTKKVYYrVxWb9eRHtDzdnDXcwg6W7ABVeOFZHVQHPLRT7ehrLGKaVsjkTyiYjsUkp90UJ5c4G5AH36eGj7vZOy0uJ49uM8Dh+rJj4syOxw3J+PrzEUt63Dceuqz04o9oazE4Bfty53ld9ZdhSeYF9pJXeN14tUuwNn+ii2cmanOx8gEif6J5RSU1p5z2IRiXXUJmKBkhbew+b4WSIii4FRQLOJwlHbWAiQkZHh1cN3M1NjefbjPJbl2ph7xQCzw/FefkHGZlA9XLhsitasJVYbvhZh+rD2LU2udQxnFujJBLIct2lAnFLqlXaWu4Qz60XdCvzn3BNEJFhEQk7fd5S9rZ3leoW+4cGkJvRoHDqoad5EKcVSayGXJ0fQ0x3nC3VBF0wUSqmDjuXFqzFqFHEi0t62nWeAqSKyB5jqeIyIxInIcsc50cB6EbECXwHLlFIr21mu18hMjSW34DgHjlRe+GRN8yDffHeUw8eq9ZIdbuSCiUJEZjm+0PcDn2PMe1jRnkKVUmVKqclKqWTHz3LH8zal1AzH/X1KqTTHLUUp9XR7yvQ2Mx0TkJZt1bUKzbtkWwsJ8LUwdaiebOkunGl6+i0wGtitlOoHTAY2uDQq7YLiw4LI6NuTbKvN7FA0rcPUN9hZmlvIpMFRhATq0WHuwplEUaeUKgMsImJRSq0B0l0cl+aEzNRYdhVVsKe4wuxQNK1DbNpfzpGTp5ilm53cijOJ4piIdMcYbfSOiLwItDI9VussM1JjsQhk605tzUss2WKje4AvEwfrTTTdiTOJYjZQBTwMrAT2YoyA0kwWFRLIZf3CWWq1oZRXjwjWuoDaejsrthUybWg0gX7uv7JtV9JiohCRJBEZp5SqVErZlVL1Sqm/AVuAsM4LUWtNVloc+45UsqNQL+irebYvdpdyoqZej3ZyQ63VKF7AWLn1XFWOY5obuHpYDD4WIduqm580z5adayOsmx/jkyPMDkU7R2uJIlEplXvuk0qpHIzlwTU30CvYn/FJESzN1c1Pmueqrm3gkx3FTB8Wi5+PMy3iWmdq7X+ktZW49AJDbiQzNZaCo9VsOXTM7FA07aKs3llMVW2DHu3kplpLFF+LyI/OfVJE7sTYM1tzE9NSYvD3seglPTSPlW21ERUSwKh+7rlvd1fX2qKADwGLReRmziSGDMAfuNbVgWnO6xHkx5WDIlmWW8jjM4ZgsegVTTXPcby6jrV5pfxgdF989O+uW2qxRqGUKlZKjQV+jbFsxwHg10qpMUqpos4JT3NWZmosRSdqyDl43o6ymubWVm0vorbBTlaa3qDIXTmzcdEaYE0nxKK1w5Qh0QT6Wci22nT1XfMoS6w2evcKIr23HnXvrvTwAi8RHODL5MHRLN9aSH2D3exwNM0pR06e4su9ZWSlxiF6Eyi3pROFF8lKi6WsspaN+8rNDkXTnLJiayENdsWsdD3ayZ3pROFFJgyKItjfR68oq3mMbGshyVHdGRQdYnYoWit0ovAigX4+TEuJYeX2ImrrdfOT5t5sx6r56kA5s9J0s5O7MyVRiMj/iMh2EbGLSEYr510tInkiki8iP+/MGD1VZmosx6vrWJ9fanYomtaqZY55P3ptJ/dnVo1iG3AdxtLlzRIRH2AeMB0YCtwkIkM7JzzPdXlyJKGBvizVaz9pbm6J1UZqQg8SI4LNDkW7AFMShVJqp1Iq7wKnjQLyHVui1gKLMJY811rh72th+rBYVu0opqauwexwNK1Z+49UsvXwcbJSdW3CE7hzH0U8cKjJ4wLHc80SkbkikiMiOaWlXbvZJTMtlpOn6lmbV2J2KJrWrNMDLjL1JDuP4LJEISKrRWRbMzdnawXN9W61uDyqUmqhUipDKZURGRl5cUF7iTH9wwkP9tc732luSSnFEquNUYm9iO2h1xf1BBecmX2xlFJT2vkWBUDvJo8TAD3u0wm+PhamD4/hw80FVJ6qJzjAZf/NmtZmu4oqyC85yW+vGWZ2KJqT3Lnp6WsgWUT6iYg/cCOwxOSYPEZWahw1dXY+3aWbnzT3km214WMRZgyLMTsUzUlmDY+9VkQKgDHAMhH52PF8nIgsB1BK1QP3Ax8DO4H3lVLbzYjXE12a2Ivo0AA9+U5zK0opsnNtjEuKILx7gNnhaE4ypU1CKbUYWNzM8zZgRpPHy4HlnRia17BYhJnD4/jHxoOcqKkjNNDP7JA0jS2HjnGovJoHJiWbHYrWBu7c9KS1U2ZaLLUNdlZtLzY7FE0DjLkT/r4WrtLNTh5FJwovdknvMOLDgnTzk+YWGuyKZbmFTBwUqWu4HkYnCi8mImSlxbEh/wjllbVmh6N1cZv2l1FScUov2eGBdKLwcpmpsdTbFSu36U0JNXNlWwvp5u/D5MHRZoeitZFOFF4uJS6U/hHBLM3VzU+aeWrr7azYVsjUodEE+fuYHY7WRjpReDkRITM1lo37yiipqDE7HK2L2pB/hGNVdczSzU4eSSeKLiArLQ67ghVbdfOTZo4lVhs9gvy4PLlrL6/jqXSi6AKSo0MYFB2iRz9ppqipa2DV9iKmD4vB31d/5Xgi/b/WRWSlxZJz8Ci2Y9Vmh6J1MZ/tKqGytkGPdvJgOlF0EZmOdf+X6RVltU62ZIuNiO4BjO4fbnYo2kXSiaKLSIwIZnh8D7L16CetE1XU1PFZXgmZqbH4WPS+2J5KJ4ouJCstltyC4xwsqzQ7FK2LWLW9mNp6u2528nA6UXQhMx3NT0t185PWSbJzbcSHBTGiT5jZoWjtoBNFFxIfFsTIvj316CetU5RX1rJ+zxGy0uIQ0c1Onkwnii4mMzXWscNYhdmhaF5uxbZC6u2KLL0vtsfTiaKLmTk8FhFj3R1Nc6UlW2wMiAxmaGyo2aFo7WTWDnf/IyLbRcQuIhmtnHdARLaKyBYRyenMGL1VVGggl/XrRXauDaWU2eFoXqroeA1fHSjXzU5ewqwaxTbgOuALJ86dqJRKV0q1mFC0tslKi2NfaSU7Ck+YHYrmpZbm2lAKPdrJS5iSKJRSO5VSeWaUrcH0YcaYdj36SXOV7NxCUuJCGRDZ3exQtA7g7n0UClglIptFZG5rJ4rIXBHJEZGc0tLSTgrPM/UK9mdcUgTZVt38pHW8g2WVWA8d0yvFehFfV72xiKwGmtsY93Gl1H+cfJtxSimbiEQBn4jILqVUs81VSqmFwEKAjIwM/e13AVmpsTz6YS7WguOk99Zj3FtyoqaOg0eqOFBWiV0p+kUE0y8imBC9lWeLTtdUM3Wi8BouSxRKqSkd8B42x88SEVkMjMK5fg3tAqalxPD44m1kW21dPlEcq6rlQFkVB8sqOXDE8bOskgNlVS1uIRsZEkD/iGD6RwbTP6I7/Rz3e/fqhp+Pu1fUXWvJFhsZfXsSHxZkdihaB3FZomgvEQkGLEqpCsf9acBvTA7La/QI8uOKgZEsyy3k8RlDsHjxOjxKKcormySDxqRg3D9eXXfW+XE9AukbHsxVKdH0DQ8mMbwbfcOD8bEI+0or2X+kkn2lJ9l/pJKPtxdTXnmo8bU+FqFPr270d9Q8+kcaSWRAZDCRIQFePwIor6iCvOIKfj0rxexQtA5kSqIQkWuBl4FIYJmIbFFKXSUiccAbSqkZQDSw2PGH5Qv8Uym10ox4vVVWWiyrdxaTc/Aoo/r1MjucdlFKUXryFAfLqjhwpNL4WXbmZ0VNfeO5FoG4sCASw4PJTI0lMTyYxAgjIfTu1Y1Av5a36hwYHXLec8eqatl3pJL9pZXsO3LSkUgqWZ9/hFP19sbzugf4NjZd9Y8MdiSQ7iRGBNM9wG2v2dok22rDIjBjuJ5k501M+e1USi0GFjfzvA2Y4bi/D0jr5NC6lClDogn0s7A01+YRicJuV5RUnHIkgDM1g/2O5qKq2obGc30sQu+eQfQND2ZEnzCjZhBh1AwSegYR4Ntx+zaHdfNnRB9/RvTpeV68hSdqGmsf+0or2Xekkm++O+qYx3Lm3OjQgMYaSNPaSELPII9pylJKkZ1rY+yACCJDAswOR+tA3nEZo12U4ABfJg2OYvnWQp7MHIqvm30h2e2KpVsLWZZrM/oOyiupqTtzhe7nI/Tu1Y3E8GBG9+9FYngwfcONx/Fu8AVrsQjxYUHEhwWdtwVoTV0DB8uq2H/kJHsdzVn7j1SyYmshR6vONIX5WoQ+4d0c/SFGM9b4pAh69+rW2f+cCzJWJq7ivglJZoeidTCdKLq4rNQ4lm8tYuO+csYnR5gdDmBcma7JK+HZj3ezs/AECT2DGBwTyuXJEfSNCKafIyHEhQV57B4HgX4+DIoJYVDM+U1ZRysdTVlN+kL2lVbyxZ4j1Nbb8bEIWamx/HhCUrOvN0u21Yafj3BVSnODHTVPphNFFzdxcBTB/j4szbW5RaL4an85/2/lLnIOHqVveDdevDGdrNQ4r+5sP1fPYH9GBvszsu/5TVkHy6v456aDvLPpOz7aYmPq0Gjum5hk+sg1u12xNLeQKwdG0aObHjrsbXSi6OIC/XyYOjSaFduK+M3sYfj7mtNcs+3wcZ79OI/Pd5cSHRrA09cO44aM3qY3H7kTi0XoFxHM4zOHcu+EJP765QH++uUBPtmxgXFJ4dw3IYkxA8JNGVn19YFyik7U8NiMwZ1etuZ6OlFoZKXF8dEWGxvyjzBxcFSnlr2v9CR//mQ3y3ILCevmx2PTB3Pr2MRWRx5pRq3j4akD+dEV/fnnpoO8vm4/339jE+m9w7hvYhKTB0d1ai1sidVGkOOiQ/M+OlFoXJ4cSWigL9lWW6clCtuxal5cvYcPvykgwNfC/05K4kdX9CdUz3huk+4Bvsy9YgC3jEnkX98UsODzvfzo7RwGRYdw78QBzBwe6/JBCnUNdlZsK2LykCi6+euvFG+k/1c1/H0tXD0shuVbi6ipa3Dp1XzZyVPMX7uXv288CApuGdOX+yYmEdFdD6dsj0A/H26+rC9zMnqTnWtj/pq9PLhoC39etZt7rhzA90bGd+iQ4KY25B+hvLJWr+3kxXSi0ADITI3j/ZwC1uaVcvWwjh+1UlFTxxvr9vPGun1U1zVw/cgEHpicTEJP9xvm6cl8fSxce0kCs9Pi+WRnMfPX5POLxVt58dPd/Ojy/tw0qg/BHTy5L9taSEigL1cOirzwyZpH0olCA2DsgHB6BfuTnWvr0ERRU9fA3/97kPlr8zlaVceM4TE8MnUQSVF6+WlXsliMYarThkbz5d4y5q3J53fLdvLKmnxuH9uPW8f2Jaybf7vLqalrYNX2Iq4eFuOyGotmPp0oNMC4Ep0+LIZ/f3OYqtr6drc11zXY+SCngJc+3UPRiRquGBjJo9MGMTyhRwdFrDlDRBiXFMG4pAi++e4o89fs5fnVu1n4xV5+MLovd47vR1Ro4EW//9q8UipO1TMrXTc7eTOdKLRGWWlxvLPpO1bvLLno9ubTs6mf/2Q3+49UMqJPGC/cmM7o/uEdHK3WViP69OSNWzPYVXSCV9fu5fV1+3jrywPckJHA3VcMuKjZ3tlWGxHd/Rmj/3+9mk4UWqNLE3sRHRrAUqutzYlCKcXavFKe/TiPHYUnGBwTwhu3ZDB5SJTXr5jqaQbHhPLijZfwyNSBLPh8H+9/XcC7Xx1idlocP54wgORmFj5szslT9azeWcycS3u73fIvWsfSiUJr5GMRZgyP5Z2N33Gips7poapf7S/n2Y938fWBrjub2hP1DQ/mD9cN58HJybyxbh/vbPqOf397mGmO2d5pF5jtvXpHMafq7Xpf7C5AJwrtLFlpcby14QCfbC/meyMTWj132+Hj/GlVHmvzSokKCeB31wxjzqV6NrWniekRyBOZQ7l3omO294b9rNpRzOXJEdw7IYnR/Xs1WytcYrUR1yOQkeesmqt5H50otLNc0juM+LAgsnNtLSaKfaUnee6T3SzNLaRHkDGb+pYxiQT561EvnqxXsD+PTB3I3Cv6885GY7b3Ta9v5JI+Ydw3IemsZsRjVbV8sbuUO8b30zXHLkAnCu0sIkJmWixvrtvP0cpaegafGUJpO1bNS5/u4YPNeja1N+se4MvdVw7g1rGJfLC5gNc+38tdb+cwOCaEH08wZnuv2FZEvV3pSXZdhKimu6d0VqEizwJZQC2wF7hdKXWsmfOuBl4EfDB2vnvGmffPyMhQOTk5HRhx17Lt8HEyX17PH64bzk2j+pw3m/rm0X24d0KS3pym+84UsgAAB25JREFUi6hrsJNttTF/7V7yS07SN7wbPhZBKfjsJ1fqwQpeQkQ2K6UymjtmVo3iE+AxpVS9iPwReAz4WdMTRMQHmAdMBQqAr0VkiVJqR6dH28WkxIXSLyKYf20uoOh4TeNs6u+NSODBKXo2dVfj52PhuhEJXJMez6odxcxfm09uwXEenjJQJ4kuwqytUFc1ebgRuL6Z00YB+Y4tURGRRcBsQCcKFxMRMlNjefmzfHIOHmX6sBh+Mm0gSVHus0mO1vksFuHqYTFclRLNzsIKPbu+C3GHPoo7gPeaeT4eONTkcQFwWUtvIiJzgbkAffr06cj4uqQfjulLRU09142IJzXB3E1xNPciIgyNCzU7DK0TuSxRiMhqoLlFgx5XSv3Hcc7jQD3wTnNv0cxzLXaoKKUWAgvB6KNoc8DaWaJCAvnVrBSzw9A0zQ24LFEopaa0dlxEbgUygcmq+R71AqB3k8cJgK3jItQ0TdOcYcrMKMdopp8Bs5RSVS2c9jWQLCL9RMQfuBFY0lkxapqmaQazptC+AoQAn4jIFhFZACAicSKyHEApVQ/cD3wM7ATeV0ptNyleTdO0LsusUU9JLTxvA2Y0ebwcWN5ZcWmapmnn04vyaJqmaa3SiULTNE1rlU4UmqZpWqt0otA0TdNaZcqigK4mIqXAwYt8eQRwpAPD8WT6szib/jzOpj+PM7zhs+irlIps7oBXJor2EJGcllZQ7Gr0Z3E2/XmcTX8eZ3j7Z6GbnjRN07RW6UShaZqmtUonivMtNDsAN6I/i7Ppz+Ns+vM4w6s/C91HoWmaprVK1yg0TdO0VulEoWmaprVKJwoHEblaRPJEJF9Efm52PGYSkd4iskZEdorIdhF50OyYzCYiPiLyrYgsNTsWs4lImIh8KCK7HL8jY8yOyUwi8rDj72SbiLwrIoFmx9TRdKLA+BIA5gHTgaHATSIy1NyoTFUP/EQpNQQYDdzXxT8PgAcxlrvX4EVgpVJqMJBGF/5cRCQeeADIUEoNA3ww9s7xKjpRGEYB+UqpfUqpWmARMNvkmEyjlCpUSn3juF+B8UUQb25U5hGRBGAm8IbZsZhNREKBK4A3AZRStUqpY+ZGZTpfIEhEfIFueOFOnDpRGOKBQ00eF9CFvxibEpFE+P/t3U2IVWUcx/HvrzcitRdKirIaLSkrTCukMkLTZWgtItBaBBUtNFwF2UYIQlB6W9RGCqppESoVuVDQCJJ8KZUmLZI0zDCSgsySsPy1eJ5LwyQnc0bPcOf3gWHuOfPcM/8Z5s7/Pi/n/zAV2NxuJK16EXgKONZ2IMPABOAg8HodilshaVTbQbXF9vfAcmAfcAD4xfa6dqMaekkUhY5zbsSvG5Y0GlgFLLJ9qO142iDpXuBH25+1HcswcRZwC/Cq7anAb8CIndOTdBFl9GE8cDkwStJD7UY19JIoiv3Alf2Ox9GF3cf/Q9LZlCTRa3t12/G0aDowR9K3lCHJeyS91W5IrdoP7Lfd6WGupCSOkWo2sNf2QdtHgdXAnS3HNOSSKIqtwERJ4yWdQ5mMer/lmFojSZQx6C9tP992PG2y/bTtcbZ7KH8XG2x33TvGE2X7B+A7SdfVU7OAXS2G1LZ9wO2Szquvm1l04eR+K3tmDze2/5S0AFhLWbXwmu2dLYfVpunAw0CfpB313OK6h3nEQqC3vqnaAzzScjytsb1Z0kpgG2W14Ha6sJxHSnhERESjDD1FRESjJIqIiGiURBEREY2SKCIiolESRURENMry2BiRJF0MrK+HlwF/UUpTAPxu+5TfNCXpQmCe7VdO9feKGIwsj40RT9IS4LDt5af5+/YAH9SqoxHDVoaeIgaQdLh+niHpI0nvSPpa0lJJ8yVtkdQn6ZrabqykVZK21o/px7nmjfV5OyR9LmkisBS4pp5bJmm0pPWSttXrz63P7al7P6yoex70SpotaaOk3ZKm1XZLJL0paUM9/9jp+61FN8vQU0Szm4FJwM+Uu5BX2J5WN3NaCCyi7M/wgu2PJV1FucN/0oDrPAG8ZLtzR/OZlGJ6N9meAlDLVN9v+5CkS4BNkjqlZK4FHgAep5ScmQfcBcwBFgP31XaTKXuIjAK2S1pje0TXLYvBS6KIaLbV9gEASd8AnRLSfcDM+ng2cEMp9QPA+ZLG1L08Oj4Bnql7W6y2vbtf+w4Bz0m6m1LS/Arg0vq1vbb7ahw7gfW2LakP6Ol3jfdsHwGOSPqQstfKuyf/40ckUUT8lz/6PT7W7/gY/7x+zgDuqP+gj8v225I2UzZAWivpUUoPpb/5wFjgVttHa8XazraaJxIH/Ls8fiYhY9AyRxExeOuABZ0DSVMGNpA0Adhj+2VKZeLJwK/AmH7NLqDsfXFU0kzg6pOIZa6kc+uqrhmUYaqIQUmiiBi8J4Hb6iT1Lsp8xEAPAl/UarzXA2/Y/gnYWCeolwG99TqfUnoXX51ELFuANcAm4NnMT8RQyPLYiC7R1jLf6H7pUURERKP0KCIiolF6FBER0SiJIiIiGiVRREREoySKiIholEQRERGN/gbe4WCyaUauiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from cycler import cycler\n",
    "import numpy as np\n",
    "fig, ax=plt.subplots(1)\n",
    "d=pd.DataFrame({'a':result_dynotears.mean(axis=0)[:,4,0],\n",
    "               # 'b':exten_matrix.mean(axis=0)[:,0,4],\n",
    "                'c':[cos(i+1) for i in range(time_stamp)]\n",
    "               })\n",
    "colors=plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "ax.set_prop_cycle(cycler('color', colors[:4]))\n",
    "cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "ax.plot(d)\n",
    "plt.legend([\"DYNOTEARS\" \"True coefficient\",])\n",
    "  \n",
    "# function to show the plot\n",
    "plt.xlabel(\"Time stamp\")\n",
    "plt.ylabel(\"Causal strength\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d5efe",
   "metadata": {},
   "source": [
    "## scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3828eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234567)\n",
    "def simulate_random_dag(d: int,\n",
    "                        degree: float,\n",
    "                        w_range: tuple = (1.0, 1.0)) -> nx.DiGraph:\n",
    "    \"\"\"Simulate random DAG with an expected degree by Erdos-Renyi model.\n",
    "        \n",
    "        Args:\n",
    "        d: number of nodes\n",
    "        degree: expected node degree, in + out\n",
    "        w_range: weight range +/- (low, high)\n",
    "        \n",
    "        Returns:\n",
    "        G: weighted DAG\n",
    "        \"\"\"\n",
    "    prob = float(degree) / (d - 1)\n",
    "    B = np.tril((np.random.rand(d, d) < prob).astype(float), k=-1)\n",
    "    \n",
    "    # random permutation\n",
    "    P = np.random.permutation(np.eye(d, d))  # permutes first axis only\n",
    "    B_perm = P.T.dot(B).dot(P)\n",
    "    U = np.random.uniform(low=w_range[0], high=w_range[1], size=[d, d])\n",
    "    U[np.random.rand(d, d) < 0.5] *= -1\n",
    "    W = (B_perm != 0).astype(float) * U\n",
    "    \n",
    "    # remove all in-edges (from precedent nodes) of the first node as A\n",
    "    W[:, 0] = 0\n",
    "    # remove all out-edges (from descendent nodes) of the last node as Y\n",
    "    W[d-1, :] = 0\n",
    "    # the remained nodes are the mediators M; and reset mediators if it has higher topological order than A or lower order than Y.\n",
    "    ordered_vertices = list(nx.topological_sort(nx.DiGraph(W)))\n",
    "    j = 1\n",
    "    while j < d - 1:\n",
    "        if  ordered_vertices.index(j) < ordered_vertices.index(0):\n",
    "            W[j, 1:(d - 1)] = np.zeros (d - 2)\n",
    "        if  ordered_vertices.index(j) > ordered_vertices.index(d - 1):\n",
    "            W[1:(d - 1), j] = np.zeros (d - 2)\n",
    "        j = j + 1\n",
    "    #print(\"True weighted adjacency matrix B:\\n\", W)\n",
    "    G = nx.DiGraph(W)\n",
    "    #calculate_effect(W)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd27ec8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1., -0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.],\n",
       "       [ 0.,  1., -0.,  0.,  1.],\n",
       "       [ 0., -0.,  0.,  0., -0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123456)\n",
    "base_DAG=simulate_random_dag(5,4)\n",
    "base_DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30397f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234567)\n",
    "pick_element=random.sample(range(5), 2) ## pick two location to mutate\n",
    "pick_1=np.nonzero(base_DAG)[0][pick_element[0]],np.nonzero(base_DAG)[1][pick_element[0]]\n",
    "pick_2=np.nonzero(base_DAG)[0][pick_element[1]],np.nonzero(base_DAG)[1][pick_element[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "def01471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def cos(x):\n",
    "    return ((math.cos(x/6*math.pi))/4+1)*0.8\n",
    "def quadratic(x):\n",
    "    return(-5+(10-x)**2)/200+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14d415c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_create(seed,time_stamp,set_graph):\n",
    "  np.random.seed(seed)\n",
    "  x = np.array(range(0, time_stamp))\n",
    "  #y = np.array([cos(i)+np.random.normal(0, 0.1, 1) for i in x]) #generate coefficient\n",
    "  y=np.array([cos(i) for i in x])\n",
    "  z=np.array([quadratic(i) for i in x])##edited to have multiple\n",
    "  base_DAG=set_graph \n",
    "  base_DAG[pick_1]=y[0]##edited to be coeffcient with error\n",
    "  base_DAG[pick_2]=z[0]###multiple\n",
    "  base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "  X_all = simulate_lsem(base_graph,30, 'Binary', 1,noise_scale=0.1)\n",
    "  for i in range(1,time_stamp):\n",
    "      base_DAG[pick_1]=y[i]##edited to be coeffcient with error\n",
    "      base_DAG[pick_2]=z[i]###multiple\n",
    "      base_graph=nx.from_numpy_matrix(base_DAG,create_using=nx.DiGraph)\n",
    "      X = simulate_lsem(base_graph,30, 'Binary', 1,noise_scale=0.1)\n",
    "      X_all=np.append(X_all,X,axis=0)\n",
    "      print(base_DAG)\n",
    "  return X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29e2910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_lsem(G: nx.DiGraph,\n",
    "                 n: int, A_type: str,\n",
    "                 x_dims: int = 1,\n",
    "                 noise_scale: float = 0.5,\n",
    "                 baseline: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Simulate samples from LSEM.\n",
    "        \n",
    "        Args:\n",
    "        G: weigthed DAG\n",
    "        n: number of samples\n",
    "        A_type: the type of the exposure {Binary, Gaussian}\n",
    "        x_dims: dimension of each node\n",
    "        noise_scale: noise scale parameter of Gaussian distribution in the lSEM\n",
    "        baseline: the baseline for the outcome\n",
    "        \n",
    "        Returns:\n",
    "        X: [n, d] sample matrix\n",
    "        \"\"\"\n",
    "    W = nx.to_numpy_array(G)\n",
    "    d = W.shape[0]\n",
    "    X = np.zeros([n, d, x_dims])\n",
    "    ordered_vertices = list(nx.topological_sort(G))\n",
    "    assert len(ordered_vertices) == d\n",
    "    rank_A = ordered_vertices.index(0)\n",
    "    for j in ordered_vertices:\n",
    "        if ordered_vertices.index(j) > rank_A:\n",
    "            parents = list(G.predecessors(j))\n",
    "            X[:, j, 0] = X[:, parents, 0].dot(W[parents, j]) + np.random.normal(scale=noise_scale, size=n)\n",
    "        elif ordered_vertices.index(j) < rank_A:\n",
    "            X[:, j, 0] = np.random.normal(scale=noise_scale, size=n)\n",
    "        else:\n",
    "            if A_type == 'Binary':\n",
    "                X[:, j, 0] = 2 * (np.random.binomial(1, 0.5, n) - 0.5)\n",
    "            elif A_type == 'Gaussian':\n",
    "                X[:, j, 0] = np.random.normal(scale=noise_scale, size=n)\n",
    "            else:\n",
    "                raise ValueError('unknown exposure type')\n",
    "    X[:, d-1, 0] += baseline\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4431c338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 5, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee461ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "0\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "1\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "2\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "3\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "5\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "6\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "7\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "8\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "10\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "11\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "12\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "13\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "15\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "16\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "17\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "18\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "20\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "21\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "22\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "23\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1698: RuntimeWarning: invalid value encountered in reduce\n",
      "  return asanyarray(a).trace(offset=offset, axis1=axis1, axis2=axis2, dtype=dtype, out=out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "26\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "27\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "28\n",
      "[[ 0.         -1.         -0.          0.88        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.97320508]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.795  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.9  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.72  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "[[ 0.    -1.    -0.     0.655  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.6         0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.555  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.6  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.         -1.         -0.          0.52        0.        ]\n",
      " [ 0.          0.          0.          0.         -0.        ]\n",
      " [ 0.          1.         -0.          0.          0.62679492]\n",
      " [ 0.         -0.          0.          0.         -0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "[[ 0.    -1.    -0.     0.495  0.   ]\n",
      " [ 0.     0.     0.     0.    -0.   ]\n",
      " [ 0.     1.    -0.     0.     0.7  ]\n",
      " [ 0.    -0.     0.     0.    -0.   ]\n",
      " [ 0.     0.     0.     0.     0.   ]]\n",
      "[[ 0.   -1.   -0.    0.48  0.  ]\n",
      " [ 0.    0.    0.    0.   -0.  ]\n",
      " [ 0.    1.   -0.    0.    0.8 ]\n",
      " [ 0.   -0.    0.    0.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.  ]]\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "p_orders=1\n",
    "d_vars=5\n",
    "n_var=5\n",
    "n_times=30 #no. of replicates\n",
    "time_stamp=10 #no. of timestamp\n",
    "np.random.seed(1234567) #Random seed\n",
    "seed_list=np.random.randint(1, 1000000, size=n_times)\n",
    "w_list=np.zeros((n_times,time_stamp,n_var, n_var))\n",
    "a_list=np.zeros((n_times,time_stamp,n_var, n_var))\n",
    "for replicate in range(n_times):\n",
    "  seed=seed_list[replicate]\n",
    "  X_all=data_create(seed,time_stamp,base_DAG) #create data\n",
    "  for time in range(time_stamp-1):\n",
    "    X=X_all[(time+1)*30:(time+2)*30].reshape(30,5)\n",
    "    Y=X_all[(time)*30:(time+1)*30].reshape(30,5)\n",
    "    w,a=from_numpy_dynamic(X,Y)\n",
    "    w_list[replicate,time,:,:]=w\n",
    "    a_list[replicate,time,:,:]=a\n",
    "    #np.save(\"result/dynotears_quadratic_w_noA\",w_list)\n",
    "    #np.save(\"result/dynotears_quadratic_a_noA\",a_list)\n",
    "    np.save(\"result/dynotears_full_w_noA\",w_list)\n",
    "    np.save(\"result/dynotears_full_noA\",a_list)\n",
    "  print(replicate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
